{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.utils import download_url\n",
    "import os\n",
    "import tarfile\n",
    "import hashlib\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import math\n",
    "import torchvision.models as models\n",
    "import timeit\n",
    "import random\n",
    "from PIL import ImageFilter\n",
    "device = \"cuda:0\"\n",
    "\n",
    "\n",
    "# https://github.com/fastai/imagenette\n",
    "dataset_url = 'https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz'\n",
    "dataset_filename = dataset_url.split('/')[-1]\n",
    "dataset_foldername = dataset_filename.split('.')[0]\n",
    "data_path = './data'\n",
    "dataset_filepath = os.path.join(data_path,dataset_filename)\n",
    "dataset_folderpath = os.path.join(data_path,dataset_foldername)\n",
    "\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "download = False\n",
    "if not os.path.exists(dataset_filepath):\n",
    "    download = True\n",
    "else:\n",
    "    md5_hash = hashlib.md5()\n",
    "\n",
    "\n",
    "    file = open(dataset_filepath, \"rb\")\n",
    "\n",
    "    content = file.read()\n",
    "\n",
    "    md5_hash.update(content)\n",
    "\n",
    "\n",
    "    digest = md5_hash.hexdigest()\n",
    "    if digest != 'fe2fc210e6bb7c5664d602c3cd71e612':\n",
    "        download = True\n",
    "if download:\n",
    "    download_url(dataset_url, data_path)\n",
    "\n",
    "with tarfile.open(dataset_filepath, 'r:gz') as tar:\n",
    "    tar.extractall(path=data_path)\n",
    "    \n",
    "with open(\"tmp.txt\",'w') as tmp:\n",
    "    tmp.write(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/moco')\n",
    "%tensorboard --logdir logs\n",
    "\n",
    "# !pip3 install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuplicatedCompose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img1 = img.copy()\n",
    "        img2 = img.copy()\n",
    "        for t in self.transforms:\n",
    "            img1 = t(img1)\n",
    "            img2 = t(img2)\n",
    "        return img1, img2\n",
    "\n",
    "class TwoCropsTransform:\n",
    "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
    "\n",
    "    def __init__(self, base_transform):\n",
    "        self.base_transform = base_transform\n",
    "\n",
    "    def __call__(self, x):\n",
    "        q = self.base_transform(x)\n",
    "        k = self.base_transform(x)\n",
    "        return [q, k]\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + '(\\n\\t'\n",
    "        format_string += self.base_transform.__repr__().replace('\\n', '\\n\\t')\n",
    "        format_string += '\\n)'\n",
    "        return format_string\n",
    "    \n",
    "    \n",
    "class GaussianBlur(object):\n",
    "    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n",
    "\n",
    "    def __init__(self, sigma=[.1, 2.]):\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, x):\n",
    "        sigma = random.uniform(self.sigma[0], self.sigma[1])\n",
    "        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "\n",
    "\n",
    "image_size = 224\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "augmentation = [\n",
    "    transforms.RandomResizedCrop(image_size, scale=(0.2, 1.)),\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n",
    "    ], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "]\n",
    "\n",
    "train_transform = TwoCropsTransform(transforms.Compose(augmentation))\n",
    "\n",
    "dataset_train = torchvision.datasets.ImageFolder(os.path.join(dataset_folderpath,'train'), train_transform)\n",
    "dataset_test = torchvision.datasets.ImageFolder(os.path.join(dataset_folderpath,'val'), train_transform)\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset_train,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Moco2(nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        super(Moco2, self).__init__()\n",
    "        self.moco = encoder\n",
    "        self.hidden_dim = encoder.fc.weight.shape[1]\n",
    "        self.linear = nn.Linear(self.hidden_dim,self.hidden_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.fc = nn.Sequential(self.linear,self.activation,encoder.fc)\n",
    "        self.moco.fc = self.fc\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.moco(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# network_q = models.resnet50(num_classes=128)\n",
    "# network_q = network_q.to(device)\n",
    "# network_k = models.resnet50(num_classes=128)\n",
    "\n",
    "network_q = Moco2(models.resnet50(num_classes=128))\n",
    "network_q.load_state_dict(torch.load(\"./Untitled Folder/new_model_q_epoch_720.pt\"))\n",
    "network_q = network_q.to(device)\n",
    "network_k = Moco2(models.resnet50(num_classes=128))\n",
    "network_k.load_state_dict(torch.load(\"./Untitled Folder/new_model_k_epoch_720.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 896\n",
    "dim = 128\n",
    "\n",
    "class KeysQueue():\n",
    "    def __init__(self):\n",
    "        self.data = torch.randn(K, dim).to(device)\n",
    "        self.queue_ptr = 0\n",
    "#     def enqueue(self, k):\n",
    "#         self.data =  torch.cat([self.data, k], dim=0)\n",
    "\n",
    "#     def dequeue(self):\n",
    "#         if len(self.data) > K:\n",
    "#             self.data = self.data[-K:]\n",
    "#         else:\n",
    "#             return\n",
    "#     def clone(self):\n",
    "#         return self.data.clone()\n",
    "\n",
    "    def _dequeue_and_enqueue(self, keys):\n",
    "#         gather keys before updating queue\n",
    "#         keys = concat_all_gather(keys)\n",
    "\n",
    "        batch_size = keys.shape[0]\n",
    "\n",
    "        ptr = self.queue_ptr\n",
    "        assert K % batch_size == 0  # for simplicity\n",
    "\n",
    "        self.data[ptr:ptr + batch_size] = keys\n",
    "        ptr = (ptr + batch_size) % K  # move pointer\n",
    "\n",
    "        self.queue_ptr = ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install --upgrade wandb==0.10.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 720 !\n",
      "\n",
      "Loss : 9.828462841762166\n",
      "Starting epoch 721 !\n",
      "\n",
      "Loss : 0.7842963674441487\n",
      "Starting epoch 722 !\n",
      "\n",
      "Loss : 0.8265370349494778\n",
      "Starting epoch 723 !\n",
      "\n",
      "Loss : 0.7687063673321082\n",
      "Starting epoch 724 !\n",
      "\n",
      "Loss : 0.7704377614316487\n",
      "Starting epoch 725 !\n",
      "\n",
      "Loss : 0.783128634804771\n",
      "Starting epoch 726 !\n",
      "\n",
      "Loss : 0.7531797535159961\n",
      "Starting epoch 727 !\n",
      "\n",
      "Loss : 0.7391796706079625\n",
      "Starting epoch 728 !\n",
      "\n",
      "Loss : 0.7844102469836773\n",
      "Starting epoch 729 !\n",
      "\n",
      "Loss : 0.7617013651092036\n",
      "Starting epoch 730 !\n",
      "\n",
      "Loss : 0.7825598593066339\n",
      "Starting epoch 731 !\n",
      "\n",
      "Loss : 0.7762201004693298\n",
      "Starting epoch 732 !\n",
      "\n",
      "Loss : 0.7667141599314553\n",
      "Starting epoch 733 !\n",
      "\n",
      "Loss : 0.7802735668461339\n",
      "Starting epoch 734 !\n",
      "\n",
      "Loss : 0.7723750510588795\n",
      "Starting epoch 735 !\n",
      "\n",
      "Loss : 0.7660526692056332\n",
      "Starting epoch 736 !\n",
      "\n",
      "Loss : 0.797857942021623\n",
      "Starting epoch 737 !\n",
      "\n",
      "Loss : 0.7744176215460511\n",
      "Starting epoch 738 !\n",
      "\n",
      "Loss : 0.773586788753263\n",
      "Starting epoch 739 !\n",
      "\n",
      "Loss : 0.760027639111694\n",
      "Starting epoch 740 !\n",
      "\n",
      "Loss : 0.7964857749792994\n",
      "Starting epoch 741 !\n",
      "\n",
      "Loss : 0.7939616322111921\n",
      "Starting epoch 742 !\n",
      "\n",
      "Loss : 0.7687973708522563\n",
      "Starting epoch 743 !\n",
      "\n",
      "Loss : 0.7859503590330785\n",
      "Starting epoch 744 !\n",
      "\n",
      "Loss : 0.79425438670885\n",
      "Starting epoch 745 !\n",
      "\n",
      "Loss : 0.7881265343451986\n",
      "Starting epoch 746 !\n",
      "\n",
      "Loss : 0.7906237970404073\n",
      "Starting epoch 747 !\n",
      "\n",
      "Loss : 0.7682021783322704\n",
      "Starting epoch 748 !\n",
      "\n",
      "Loss : 0.7791131742957498\n",
      "Starting epoch 749 !\n",
      "\n",
      "Loss : 0.7745684877950318\n",
      "Starting epoch 750 !\n",
      "\n",
      "Loss : 0.8149870475944208\n",
      "Starting epoch 751 !\n",
      "\n",
      "Loss : 0.766665991877212\n",
      "Starting epoch 752 !\n",
      "\n",
      "Loss : 0.7532268365224203\n",
      "Starting epoch 753 !\n",
      "\n",
      "Loss : 0.7595194602499202\n",
      "Starting epoch 754 !\n",
      "\n",
      "Loss : 0.7636435198135116\n",
      "Starting epoch 755 !\n",
      "\n",
      "Loss : 0.7882487479926777\n",
      "Starting epoch 756 !\n",
      "\n",
      "Loss : 0.7936903844479801\n",
      "Starting epoch 757 !\n",
      "\n",
      "Loss : 0.7605621034190768\n",
      "Starting epoch 758 !\n",
      "\n",
      "Loss : 0.7658381429659266\n",
      "Starting epoch 759 !\n",
      "\n",
      "Loss : 0.7468071399497337\n",
      "Starting epoch 760 !\n",
      "\n",
      "Loss : 0.7246210236533158\n",
      "Starting epoch 761 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    Exception ignored in: assert self._parent_pid == os.getpid(), 'can only join a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "\n",
      "AssertionErrorTraceback (most recent call last):\n",
      ":   File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "can only join a child process    \n",
      "self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.7705439424433675\n",
      "Starting epoch 762 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.7888864303121761\n",
      "Starting epoch 763 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.7593545925860502\n",
      "Starting epoch 764 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    Exception ignored in: assert self._parent_pid == os.getpid(), 'can only join a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "AssertionError\n",
      ": Traceback (most recent call last):\n",
      "can only join a child process  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.7556078496838914\n",
      "Starting epoch 765 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.7431464272291481\n",
      "Starting epoch 766 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.7589884357792991\n",
      "Starting epoch 767 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.7788409462996891\n",
      "Starting epoch 768 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.6962699032559687\n",
      "Starting epoch 769 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "        self._shutdown_workers()\n",
      "self._shutdown_workers()  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)    \n",
      "w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'    \n",
      "assert self._parent_pid == os.getpid(), 'can only join a child process'AssertionError\n",
      ": AssertionErrorcan only join a child process: can only join a child process\n",
      "\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.7555094430235778\n",
      "Starting epoch 770 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.7327621187888035\n",
      "Starting epoch 771 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.7138067212234549\n",
      "Starting epoch 772 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "\n",
      "Traceback (most recent call last):\n",
      "      File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "    AssertionErrorself._shutdown_workers(): \n",
      "can only join a child process  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.7596369610757244\n",
      "Starting epoch 773 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.7179522676532771\n",
      "Starting epoch 774 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.7374315146280794\n",
      "Starting epoch 775 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "    Traceback (most recent call last):\n",
      "self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "        self._shutdown_workers()w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "        w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "AssertionError    assert self._parent_pid == os.getpid(), 'can only join a child process': \n",
      "can only join a child process\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.7583241109945336\n",
      "Starting epoch 776 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "    Traceback (most recent call last):\n",
      "assert self._parent_pid == os.getpid(), 'can only join a child process'  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "\n",
      "AssertionError    : self._shutdown_workers()\n",
      "can only join a child process  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.7213829593593571\n",
      "Starting epoch 777 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.7492334159458576\n",
      "Starting epoch 778 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.7371237251628824\n",
      "Starting epoch 779 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "assert self._parent_pid == os.getpid(), 'can only join a child process'  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "\n",
      "    AssertionErrorself._shutdown_workers(): \n",
      "can only join a child process  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "\n",
      "Traceback (most recent call last):\n",
      "      File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError    self._shutdown_workers(): \n",
      "can only join a child process  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.7390756819929395\n",
      "Starting epoch 780 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.760055526786921\n",
      "Starting epoch 781 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.731624361609115\n",
      "Starting epoch 782 !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4ffdb2b560>assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "AssertionError:     can only join a child processself._shutdown_workers()\n",
      "\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/guy.shapira/miniconda3/envs/inv/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.7048228312106359\n",
      "Starting epoch 783 !\n",
      "\n",
      "Loss : 0.7317454993319349\n",
      "Starting epoch 784 !\n",
      "\n",
      "Loss : 0.7311820706137183\n",
      "Starting epoch 785 !\n",
      "\n",
      "Loss : 0.7141827588178673\n",
      "Starting epoch 786 !\n",
      "\n",
      "Loss : 0.7308354045258088\n",
      "Starting epoch 787 !\n",
      "\n",
      "Loss : 0.7167634325368064\n",
      "Starting epoch 788 !\n",
      "\n",
      "Loss : 0.7392583051506354\n",
      "Starting epoch 789 !\n",
      "\n",
      "Loss : 0.7134620048561875\n",
      "Starting epoch 790 !\n",
      "\n",
      "Loss : 0.7257950502593501\n",
      "Starting epoch 791 !\n",
      "\n",
      "Loss : 0.7250279421303548\n",
      "Starting epoch 792 !\n",
      "\n",
      "Loss : 0.7091347267027615\n",
      "Starting epoch 793 !\n",
      "\n",
      "Loss : 0.7664200361488628\n",
      "Starting epoch 794 !\n",
      "\n",
      "Loss : 0.7034972695266308\n",
      "Starting epoch 795 !\n",
      "\n",
      "Loss : 0.7367635201029226\n",
      "Starting epoch 796 !\n",
      "\n",
      "Loss : 0.7309630742283906\n",
      "Starting epoch 797 !\n",
      "\n",
      "Loss : 0.685928385071203\n",
      "Starting epoch 798 !\n",
      "\n",
      "Loss : 0.7141605297318933\n",
      "Starting epoch 799 !\n",
      "\n",
      "Loss : 0.7198294111255075\n",
      "Starting epoch 800 !\n",
      "\n",
      "Loss : 0.6857879672731672\n",
      "Starting epoch 801 !\n",
      "\n",
      "Loss : 0.7318890510367698\n",
      "Starting epoch 802 !\n",
      "\n",
      "Loss : 0.724220195595099\n",
      "Starting epoch 803 !\n",
      "\n",
      "Loss : 0.6990861629142242\n",
      "Starting epoch 804 !\n",
      "\n",
      "Loss : 0.7046566755593229\n",
      "Starting epoch 805 !\n",
      "\n",
      "Loss : 0.6916215537356681\n",
      "Starting epoch 806 !\n",
      "\n",
      "Loss : 0.7230213406134625\n",
      "Starting epoch 807 !\n",
      "\n",
      "Loss : 0.6930278172703828\n",
      "Starting epoch 808 !\n",
      "\n",
      "Loss : 0.7031160722784444\n",
      "Starting epoch 809 !\n",
      "\n",
      "Loss : 0.6997629884554415\n",
      "Starting epoch 810 !\n",
      "\n",
      "Loss : 0.6930880881085688\n",
      "Starting epoch 811 !\n",
      "\n",
      "Loss : 0.7111042275720713\n",
      "Starting epoch 812 !\n",
      "\n",
      "Loss : 0.6896903879788457\n",
      "Starting epoch 813 !\n",
      "\n",
      "Loss : 0.713013617562599\n",
      "Starting epoch 814 !\n",
      "\n",
      "Loss : 0.7380268377106206\n",
      "Starting epoch 815 !\n",
      "\n",
      "Loss : 0.6951441945267373\n",
      "Starting epoch 816 !\n",
      "\n",
      "Loss : 0.66385356828469\n",
      "Starting epoch 817 !\n",
      "\n",
      "Loss : 0.6438417118422839\n",
      "Starting epoch 818 !\n",
      "\n",
      "Loss : 0.7099568111961391\n",
      "Starting epoch 819 !\n",
      "\n",
      "Loss : 0.6549576677027202\n",
      "Starting epoch 820 !\n",
      "\n",
      "Loss : 0.6801026611506533\n",
      "Starting epoch 821 !\n",
      "\n",
      "Loss : 0.7081964873537725\n",
      "Starting epoch 822 !\n",
      "\n",
      "Loss : 0.7282388117037663\n",
      "Starting epoch 823 !\n",
      "\n",
      "Loss : 0.6908492327344661\n",
      "Starting epoch 824 !\n",
      "\n",
      "Loss : 0.676415895726405\n",
      "Starting epoch 825 !\n",
      "\n",
      "Loss : 0.6874128632804974\n",
      "Starting epoch 826 !\n",
      "\n",
      "Loss : 0.6884354127913105\n",
      "Starting epoch 827 !\n",
      "\n",
      "Loss : 0.6947104677456577\n",
      "Starting epoch 828 !\n",
      "\n",
      "Loss : 0.6864023893868842\n",
      "Starting epoch 829 !\n",
      "\n",
      "Loss : 0.6801045492392819\n",
      "Starting epoch 830 !\n",
      "\n",
      "Loss : 0.6837143001913213\n",
      "Starting epoch 831 !\n",
      "\n",
      "Loss : 0.710281473438756\n",
      "Starting epoch 832 !\n",
      "\n",
      "Loss : 0.7162301070025178\n",
      "Starting epoch 833 !\n",
      "\n",
      "Loss : 0.7029555914353351\n",
      "Starting epoch 834 !\n",
      "\n",
      "Loss : 0.6832265343998565\n",
      "Starting epoch 835 !\n",
      "\n",
      "Loss : 0.6694168691732445\n",
      "Starting epoch 836 !\n",
      "\n",
      "Loss : 0.6710203135905622\n",
      "Starting epoch 837 !\n",
      "\n",
      "Loss : 0.6646486895830452\n",
      "Starting epoch 838 !\n",
      "\n",
      "Loss : 0.6385511860352795\n",
      "Starting epoch 839 !\n",
      "\n",
      "Loss : 0.7142718199159013\n",
      "Starting epoch 840 !\n",
      "\n",
      "Loss : 0.681064057917822\n",
      "Starting epoch 841 !\n",
      "\n",
      "Loss : 0.6655151621014083\n",
      "Starting epoch 842 !\n",
      "\n",
      "Loss : 0.6546785091461779\n",
      "Starting epoch 843 !\n",
      "\n",
      "Loss : 0.6552353626003071\n",
      "Starting epoch 844 !\n",
      "\n",
      "Loss : 0.6753525731920385\n",
      "Starting epoch 845 !\n",
      "\n",
      "Loss : 0.6522788069888849\n",
      "Starting epoch 846 !\n",
      "\n",
      "Loss : 0.6252248995766347\n",
      "Starting epoch 847 !\n",
      "\n",
      "Loss : 0.6507714155579911\n",
      "Starting epoch 848 !\n",
      "\n",
      "Loss : 0.6810550799175185\n",
      "Starting epoch 849 !\n",
      "\n",
      "Loss : 0.660407310034953\n",
      "Starting epoch 850 !\n",
      "\n",
      "Loss : 0.6548577091929053\n",
      "Starting epoch 851 !\n",
      "\n",
      "Loss : 0.6664951828872265\n",
      "Starting epoch 852 !\n",
      "\n",
      "Loss : 0.6945629953121653\n",
      "Starting epoch 853 !\n",
      "\n",
      "Loss : 0.6483181021651443\n",
      "Starting epoch 854 !\n",
      "\n",
      "Loss : 0.6350324599921298\n",
      "Starting epoch 855 !\n",
      "\n",
      "Loss : 0.6516900022013657\n",
      "Starting epoch 856 !\n",
      "\n",
      "Loss : 0.6455237626218472\n",
      "Starting epoch 857 !\n",
      "\n",
      "Loss : 0.6336199532763488\n",
      "Starting epoch 858 !\n",
      "\n",
      "Loss : 0.6895980630196682\n",
      "Starting epoch 859 !\n",
      "\n",
      "Loss : 0.6266952544248023\n",
      "Starting epoch 860 !\n",
      "\n",
      "Loss : 0.6490498495345213\n",
      "Starting epoch 861 !\n",
      "\n",
      "Loss : 0.6577848072360162\n",
      "Starting epoch 862 !\n",
      "\n",
      "Loss : 0.6469315602665856\n",
      "Starting epoch 863 !\n",
      "\n",
      "Loss : 0.6429466601131725\n",
      "Starting epoch 864 !\n",
      "\n",
      "Loss : 0.6549069100902194\n",
      "Starting epoch 865 !\n",
      "\n",
      "Loss : 0.626504874756547\n",
      "Starting epoch 866 !\n",
      "\n",
      "Loss : 0.6360953780664068\n",
      "Starting epoch 867 !\n",
      "\n",
      "Loss : 0.6390482978958661\n",
      "Starting epoch 868 !\n",
      "\n",
      "Loss : 0.6296305443559375\n",
      "Starting epoch 869 !\n",
      "\n",
      "Loss : 0.6537336975741549\n",
      "Starting epoch 870 !\n",
      "\n",
      "Loss : 0.6852453969368318\n",
      "Starting epoch 871 !\n",
      "\n",
      "Loss : 0.6354743576779658\n",
      "Starting epoch 872 !\n",
      "\n",
      "Loss : 0.6356202932644863\n",
      "Starting epoch 873 !\n",
      "\n",
      "Loss : 0.6357500345325794\n",
      "Starting epoch 874 !\n",
      "\n",
      "Loss : 0.656691447204473\n",
      "Starting epoch 875 !\n",
      "\n",
      "Loss : 0.6495141180194154\n",
      "Starting epoch 876 !\n",
      "\n",
      "Loss : 0.66593033703817\n",
      "Starting epoch 877 !\n",
      "\n",
      "Loss : 0.6435429176100257\n",
      "Starting epoch 878 !\n",
      "\n",
      "Loss : 0.6195107729864769\n",
      "Starting epoch 879 !\n",
      "\n",
      "Loss : 0.6490906355332355\n",
      "Starting epoch 880 !\n",
      "\n",
      "Loss : 0.6166531905835989\n",
      "Starting epoch 881 !\n",
      "\n",
      "Loss : 0.6435082875141481\n",
      "Starting epoch 882 !\n",
      "\n",
      "Loss : 0.6189157421491585\n",
      "Starting epoch 883 !\n",
      "\n",
      "Loss : 0.615286666317051\n",
      "Starting epoch 884 !\n",
      "\n",
      "Loss : 0.6439960388099255\n",
      "Starting epoch 885 !\n",
      "\n",
      "Loss : 0.6354476875391136\n",
      "Starting epoch 886 !\n",
      "\n",
      "Loss : 0.6451947188296285\n",
      "Starting epoch 887 !\n",
      "\n",
      "Loss : 0.6222757322042167\n",
      "Starting epoch 888 !\n",
      "\n",
      "Loss : 0.6513890048273566\n",
      "Starting epoch 889 !\n",
      "\n",
      "Loss : 0.6181981782523953\n",
      "Starting epoch 890 !\n",
      "\n",
      "Loss : 0.6330701111733508\n",
      "Starting epoch 891 !\n",
      "\n",
      "Loss : 0.6224052127526731\n",
      "Starting epoch 892 !\n",
      "\n",
      "Loss : 0.6136975084640541\n",
      "Starting epoch 893 !\n",
      "\n",
      "Loss : 0.6205242083591669\n",
      "Starting epoch 894 !\n",
      "\n",
      "Loss : 0.6320295162549635\n",
      "Starting epoch 895 !\n",
      "\n",
      "Loss : 0.6162137362827249\n",
      "Starting epoch 896 !\n",
      "\n",
      "Loss : 0.6085466098825948\n",
      "Starting epoch 897 !\n",
      "\n",
      "Loss : 0.6336532268597155\n",
      "Starting epoch 898 !\n",
      "\n",
      "Loss : 0.6254628274311014\n",
      "Starting epoch 899 !\n",
      "\n",
      "Loss : 0.6449691432268441\n",
      "Starting epoch 900 !\n",
      "\n",
      "Loss : 0.648243114960437\n",
      "Starting epoch 901 !\n",
      "\n",
      "Loss : 0.6231456015791211\n",
      "Starting epoch 902 !\n",
      "\n",
      "Loss : 0.6356957988674138\n",
      "Starting epoch 903 !\n",
      "\n",
      "Loss : 0.5923135867532419\n",
      "Starting epoch 904 !\n",
      "\n",
      "Loss : 0.6196367841999547\n",
      "Starting epoch 905 !\n",
      "\n",
      "Loss : 0.6027152436931117\n",
      "Starting epoch 906 !\n",
      "\n",
      "Loss : 0.6210557391651633\n",
      "Starting epoch 907 !\n",
      "\n",
      "Loss : 0.6225764364206872\n",
      "Starting epoch 908 !\n",
      "\n",
      "Loss : 0.6378704187821369\n",
      "Starting epoch 909 !\n",
      "\n",
      "Loss : 0.594327293691181\n",
      "Starting epoch 910 !\n",
      "\n",
      "Loss : 0.6207996738605759\n",
      "Starting epoch 911 !\n",
      "\n",
      "Loss : 0.589495412549194\n",
      "Starting epoch 912 !\n",
      "\n",
      "Loss : 0.6288371416581732\n",
      "Starting epoch 913 !\n",
      "\n",
      "Loss : 0.5852813400378843\n",
      "Starting epoch 914 !\n",
      "\n",
      "Loss : 0.5702310644444966\n",
      "Starting epoch 915 !\n",
      "\n",
      "Loss : 0.5840331174078441\n",
      "Starting epoch 916 !\n",
      "\n",
      "Loss : 0.5989426276108034\n",
      "Starting epoch 917 !\n",
      "\n",
      "Loss : 0.6036398458440287\n",
      "Starting epoch 918 !\n",
      "\n",
      "Loss : 0.6137612307963728\n",
      "Starting epoch 919 !\n",
      "\n",
      "Loss : 0.570899710768745\n",
      "Starting epoch 920 !\n",
      "\n",
      "Loss : 0.5739486505385158\n",
      "Starting epoch 921 !\n",
      "\n",
      "Loss : 0.5853191747957346\n",
      "Starting epoch 922 !\n",
      "\n",
      "Loss : 0.6161886914854958\n",
      "Starting epoch 923 !\n",
      "\n",
      "Loss : 0.588373671380841\n",
      "Starting epoch 924 !\n",
      "\n",
      "Loss : 0.5712577297168524\n",
      "Starting epoch 925 !\n",
      "\n",
      "Loss : 0.5931382251231849\n",
      "Starting epoch 926 !\n",
      "\n",
      "Loss : 0.6015212859223489\n",
      "Starting epoch 927 !\n",
      "\n",
      "Loss : 0.5917790225979422\n",
      "Starting epoch 928 !\n",
      "\n",
      "Loss : 0.6084498679962288\n",
      "Starting epoch 929 !\n",
      "\n",
      "Loss : 0.5843341636414431\n",
      "Starting epoch 930 !\n",
      "\n",
      "Loss : 0.5894330961971866\n",
      "Starting epoch 931 !\n",
      "\n",
      "Loss : 0.6029137494612713\n",
      "Starting epoch 932 !\n",
      "\n",
      "Loss : 0.6082225458151629\n",
      "Starting epoch 933 !\n",
      "\n",
      "Loss : 0.5855253481743287\n",
      "Starting epoch 934 !\n",
      "\n",
      "Loss : 0.5957535042041013\n",
      "Starting epoch 935 !\n",
      "\n",
      "Loss : 0.5576434951452982\n",
      "Starting epoch 936 !\n",
      "\n",
      "Loss : 0.5746947678984428\n",
      "Starting epoch 937 !\n",
      "\n",
      "Loss : 0.5821403877264788\n",
      "Starting epoch 938 !\n",
      "\n",
      "Loss : 0.5772336992074032\n",
      "Starting epoch 939 !\n",
      "\n",
      "Loss : 0.5917364570762025\n",
      "Starting epoch 940 !\n",
      "\n",
      "Loss : 0.5615207724222521\n",
      "Starting epoch 941 !\n",
      "\n",
      "Loss : 0.5951562198449154\n",
      "Starting epoch 942 !\n",
      "\n",
      "Loss : 0.5721728794631504\n",
      "Starting epoch 943 !\n",
      "\n",
      "Loss : 0.5609178070713874\n",
      "Starting epoch 944 !\n",
      "\n",
      "Loss : 0.5513717086136747\n",
      "Starting epoch 945 !\n",
      "\n",
      "Loss : 0.5732897343684216\n",
      "Starting epoch 946 !\n",
      "\n",
      "Loss : 0.5822685508906436\n",
      "Starting epoch 947 !\n",
      "\n",
      "Loss : 0.6030282832327343\n",
      "Starting epoch 948 !\n",
      "\n",
      "Loss : 0.5897035553139083\n",
      "Starting epoch 949 !\n",
      "\n",
      "Loss : 0.5845916541863461\n",
      "Starting epoch 950 !\n",
      "\n",
      "Loss : 0.5734675456674732\n",
      "Starting epoch 951 !\n",
      "\n",
      "Loss : 0.550003146942781\n",
      "Starting epoch 952 !\n",
      "\n",
      "Loss : 0.5967509596526217\n",
      "Starting epoch 953 !\n",
      "\n",
      "Loss : 0.546640033827347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 954 !\n",
      "\n",
      "Loss : 0.5576116155807663\n",
      "Starting epoch 955 !\n",
      "\n",
      "Loss : 0.52868520139026\n",
      "Starting epoch 956 !\n",
      "\n",
      "Loss : 0.5718388618255148\n",
      "Starting epoch 957 !\n",
      "\n",
      "Loss : 0.5509556100076559\n",
      "Starting epoch 958 !\n",
      "\n",
      "Loss : 0.5526843623441904\n",
      "Starting epoch 959 !\n",
      "\n",
      "Loss : 0.5615994848158895\n",
      "Starting epoch 960 !\n",
      "\n",
      "Loss : 0.5580108042071465\n",
      "Starting epoch 961 !\n",
      "\n",
      "Loss : 0.5716348787148794\n",
      "Starting epoch 962 !\n",
      "\n",
      "Loss : 0.5457124280280807\n",
      "Starting epoch 963 !\n",
      "\n",
      "Loss : 0.5519044138744574\n",
      "Starting epoch 964 !\n",
      "\n",
      "Loss : 0.5811557957307011\n",
      "Starting epoch 965 !\n",
      "\n",
      "Loss : 0.5732317934839093\n",
      "Starting epoch 966 !\n",
      "\n",
      "Loss : 0.577310569432317\n",
      "Starting epoch 967 !\n",
      "\n",
      "Loss : 0.5637615799498396\n",
      "Starting epoch 968 !\n",
      "\n",
      "Loss : 0.5556383217070379\n",
      "Starting epoch 969 !\n",
      "\n",
      "Loss : 0.5596842054201632\n",
      "Starting epoch 970 !\n",
      "\n",
      "Loss : 0.5493642965547082\n",
      "Starting epoch 971 !\n",
      "\n",
      "Loss : 0.5636287231226357\n",
      "Starting epoch 972 !\n",
      "\n",
      "Loss : 0.5449746795454804\n",
      "Starting epoch 973 !\n",
      "\n",
      "Loss : 0.5520699318168926\n",
      "Starting epoch 974 !\n",
      "\n",
      "Loss : 0.5494794198850386\n",
      "Starting epoch 975 !\n",
      "\n",
      "Loss : 0.5443662254988741\n",
      "Starting epoch 976 !\n",
      "\n",
      "Loss : 0.5276098813937635\n",
      "Starting epoch 977 !\n",
      "\n",
      "Loss : 0.5433002102131747\n",
      "Starting epoch 978 !\n",
      "\n",
      "Loss : 0.5308899964605059\n",
      "Starting epoch 979 !\n",
      "\n",
      "Loss : 0.5762316635271318\n",
      "Starting epoch 980 !\n",
      "\n",
      "Loss : 0.5167023741266354\n",
      "Starting epoch 981 !\n",
      "\n",
      "Loss : 0.5733962043815729\n",
      "Starting epoch 982 !\n",
      "\n",
      "Loss : 0.5289757818389101\n",
      "Starting epoch 983 !\n",
      "\n",
      "Loss : 0.5477374726209511\n",
      "Starting epoch 984 !\n",
      "\n",
      "Loss : 0.5470174544928025\n",
      "Starting epoch 985 !\n",
      "\n",
      "Loss : 0.5364766196936978\n",
      "Starting epoch 986 !\n",
      "\n",
      "Loss : 0.5291014688761055\n",
      "Starting epoch 987 !\n",
      "\n",
      "Loss : 0.5453044470070171\n",
      "Starting epoch 988 !\n",
      "\n",
      "Loss : 0.5448823156608206\n",
      "Starting epoch 989 !\n",
      "\n",
      "Loss : 0.5128794864935129\n",
      "Starting epoch 990 !\n",
      "\n",
      "Loss : 0.5386556614012945\n",
      "Starting epoch 991 !\n",
      "\n",
      "Loss : 0.5512574527944837\n",
      "Starting epoch 992 !\n",
      "\n",
      "Loss : 0.5593486471849234\n",
      "Starting epoch 993 !\n",
      "\n",
      "Loss : 0.5349567233502459\n",
      "Starting epoch 994 !\n",
      "\n",
      "Loss : 0.5219954220818824\n",
      "Starting epoch 995 !\n",
      "\n",
      "Loss : 0.5767059763069866\n",
      "Starting epoch 996 !\n",
      "\n",
      "Loss : 0.53288611262834\n",
      "Starting epoch 997 !\n",
      "\n",
      "Loss : 0.5379759363171195\n",
      "Starting epoch 998 !\n",
      "\n",
      "Loss : 0.5037307668299902\n",
      "Starting epoch 999 !\n",
      "\n",
      "Loss : 0.5362358240245961\n",
      "Starting epoch 1000 !\n",
      "\n",
      "Loss : 0.528211384808936\n",
      "Starting epoch 1001 !\n",
      "\n",
      "Loss : 0.5338569631179174\n",
      "Starting epoch 1002 !\n",
      "\n",
      "Loss : 0.5147280813682646\n",
      "Starting epoch 1003 !\n",
      "\n",
      "Loss : 0.5473492237783614\n",
      "Starting epoch 1004 !\n",
      "\n",
      "Loss : 0.5163799361104057\n",
      "Starting epoch 1005 !\n",
      "\n",
      "Loss : 0.5437499184389504\n",
      "Starting epoch 1006 !\n",
      "\n",
      "Loss : 0.5342210776546374\n",
      "Starting epoch 1007 !\n",
      "\n",
      "Loss : 0.5339899638883111\n",
      "Starting epoch 1008 !\n",
      "\n",
      "Loss : 0.5250992702991784\n",
      "Starting epoch 1009 !\n",
      "\n",
      "Loss : 0.5062385685995322\n",
      "Starting epoch 1010 !\n",
      "\n",
      "Loss : 0.5054432434492371\n",
      "Starting epoch 1011 !\n",
      "\n",
      "Loss : 0.5333953412617145\n",
      "Starting epoch 1012 !\n",
      "\n",
      "Loss : 0.5259132164270699\n",
      "Starting epoch 1013 !\n",
      "\n",
      "Loss : 0.5229314804888096\n",
      "Starting epoch 1014 !\n",
      "\n",
      "Loss : 0.5217502199265421\n",
      "Starting epoch 1015 !\n",
      "\n",
      "Loss : 0.524255607302497\n",
      "Starting epoch 1016 !\n",
      "\n",
      "Loss : 0.5358797830789268\n",
      "Starting epoch 1017 !\n",
      "\n",
      "Loss : 0.519948113430925\n",
      "Starting epoch 1018 !\n",
      "\n",
      "Loss : 0.5100375730164197\n",
      "Starting epoch 1019 !\n",
      "\n",
      "Loss : 0.5295597229685102\n",
      "Starting epoch 1020 !\n",
      "\n",
      "Loss : 0.5379556133633568\n",
      "Starting epoch 1021 !\n",
      "\n",
      "Loss : 0.514730649639149\n",
      "Starting epoch 1022 !\n",
      "\n",
      "Loss : 0.5567210075401124\n",
      "Starting epoch 1023 !\n",
      "\n",
      "Loss : 0.5210898523630739\n",
      "Starting epoch 1024 !\n",
      "\n",
      "Loss : 0.5095678116796779\n",
      "Starting epoch 1025 !\n",
      "\n",
      "Loss : 0.5121108583447074\n",
      "Starting epoch 1026 !\n",
      "\n",
      "Loss : 0.4776471213621347\n",
      "Starting epoch 1027 !\n",
      "\n",
      "Loss : 0.498902847166775\n",
      "Starting epoch 1028 !\n",
      "\n",
      "Loss : 0.5066898109353318\n",
      "Starting epoch 1029 !\n",
      "\n",
      "Loss : 0.5051997198539526\n",
      "Starting epoch 1030 !\n",
      "\n",
      "Loss : 0.4900904945573028\n",
      "Starting epoch 1031 !\n",
      "\n",
      "Loss : 0.5151746687637705\n",
      "Starting epoch 1032 !\n",
      "\n",
      "Loss : 0.4800980899001465\n",
      "Starting epoch 1033 !\n",
      "\n",
      "Loss : 0.5084902575226868\n",
      "Starting epoch 1034 !\n",
      "\n",
      "Loss : 0.5027978656446042\n",
      "Starting epoch 1035 !\n",
      "\n",
      "Loss : 0.4914220357630529\n",
      "Starting epoch 1036 !\n",
      "\n",
      "Loss : 0.5003058236269724\n",
      "Starting epoch 1037 !\n",
      "\n",
      "Loss : 0.47652994978184604\n",
      "Starting epoch 1038 !\n",
      "\n",
      "Loss : 0.5065873443674879\n",
      "Starting epoch 1039 !\n",
      "\n",
      "Loss : 0.504054135814005\n",
      "Starting epoch 1040 !\n",
      "\n",
      "Loss : 0.5075590193879848\n",
      "Starting epoch 1041 !\n",
      "\n",
      "Loss : 0.5055148628901462\n",
      "Starting epoch 1042 !\n",
      "\n",
      "Loss : 0.4885795764168914\n",
      "Starting epoch 1043 !\n",
      "\n",
      "Loss : 0.47600592541045883\n",
      "Starting epoch 1044 !\n",
      "\n",
      "Loss : 0.48809287854197886\n",
      "Starting epoch 1045 !\n",
      "\n",
      "Loss : 0.49809823078768595\n",
      "Starting epoch 1046 !\n",
      "\n",
      "Loss : 0.4935217953863598\n",
      "Starting epoch 1047 !\n",
      "\n",
      "Loss : 0.512047194806086\n",
      "Starting epoch 1048 !\n",
      "\n",
      "Loss : 0.4448926806652627\n",
      "Starting epoch 1049 !\n",
      "\n",
      "Loss : 0.48006160922196445\n",
      "Starting epoch 1050 !\n",
      "\n",
      "Loss : 0.47211214666869367\n",
      "Starting epoch 1051 !\n",
      "\n",
      "Loss : 0.4814207362277167\n",
      "Starting epoch 1052 !\n",
      "\n",
      "Loss : 0.45988474198344614\n",
      "Starting epoch 1053 !\n",
      "\n",
      "Loss : 0.4923889333901762\n",
      "Starting epoch 1054 !\n",
      "\n",
      "Loss : 0.5088698034789286\n",
      "Starting epoch 1055 !\n",
      "\n",
      "Loss : 0.4808913876815718\n",
      "Starting epoch 1056 !\n",
      "\n",
      "Loss : 0.48457335787160055\n",
      "Starting epoch 1057 !\n",
      "\n",
      "Loss : 0.4774821252644468\n",
      "Starting epoch 1058 !\n",
      "\n",
      "Loss : 0.4789854715876028\n",
      "Starting epoch 1059 !\n",
      "\n",
      "Loss : 0.4817944460985612\n",
      "Starting epoch 1060 !\n",
      "\n",
      "Loss : 0.497804174111003\n",
      "Starting epoch 1061 !\n",
      "\n",
      "Loss : 0.47402075683178546\n",
      "Starting epoch 1062 !\n",
      "\n",
      "Loss : 0.49397591202437474\n",
      "Starting epoch 1063 !\n",
      "\n",
      "Loss : 0.4908946653207143\n",
      "Starting epoch 1064 !\n",
      "\n",
      "Loss : 0.506450065240568\n",
      "Starting epoch 1065 !\n",
      "\n",
      "Loss : 0.4831843003123796\n",
      "Starting epoch 1066 !\n",
      "\n",
      "Loss : 0.47437327552814873\n",
      "Starting epoch 1067 !\n",
      "\n",
      "Loss : 0.46077459067308985\n",
      "Starting epoch 1068 !\n",
      "\n",
      "Loss : 0.4610290683451153\n",
      "Starting epoch 1069 !\n",
      "\n",
      "Loss : 0.4972960133941806\n",
      "Starting epoch 1070 !\n",
      "\n",
      "Loss : 0.46650642724264235\n",
      "Starting epoch 1071 !\n",
      "\n",
      "Loss : 0.46123072677323607\n",
      "Starting epoch 1072 !\n",
      "\n",
      "Loss : 0.46032917306942195\n",
      "Starting epoch 1073 !\n",
      "\n",
      "Loss : 0.4886637414697887\n",
      "Starting epoch 1074 !\n",
      "\n",
      "Loss : 0.45870135004828577\n",
      "Starting epoch 1075 !\n",
      "\n",
      "Loss : 0.476553228639421\n",
      "Starting epoch 1076 !\n",
      "\n",
      "Loss : 0.4909822551571593\n",
      "Starting epoch 1077 !\n",
      "\n",
      "Loss : 0.46449627701928015\n",
      "Starting epoch 1078 !\n",
      "\n",
      "Loss : 0.45081256056318475\n",
      "Starting epoch 1079 !\n",
      "\n",
      "Loss : 0.4815924341986779\n",
      "Starting epoch 1080 !\n",
      "\n",
      "Loss : 0.45248114647103005\n",
      "Starting epoch 1081 !\n",
      "\n",
      "Loss : 0.4562286491296729\n",
      "Starting epoch 1082 !\n",
      "\n",
      "Loss : 0.458762619771114\n",
      "Starting epoch 1083 !\n",
      "\n",
      "Loss : 0.4470800877022905\n",
      "Starting epoch 1084 !\n",
      "\n",
      "Loss : 0.490012534520253\n",
      "Starting epoch 1085 !\n",
      "\n",
      "Loss : 0.47655434855798473\n",
      "Starting epoch 1086 !\n",
      "\n",
      "Loss : 0.4653101377949423\n",
      "Starting epoch 1087 !\n",
      "\n",
      "Loss : 0.4424467523689984\n",
      "Starting epoch 1088 !\n",
      "\n",
      "Loss : 0.450288094478805\n",
      "Starting epoch 1089 !\n",
      "\n",
      "Loss : 0.45309120609241277\n",
      "Starting epoch 1090 !\n",
      "\n",
      "Loss : 0.47719367213395175\n",
      "Starting epoch 1091 !\n",
      "\n",
      "Loss : 0.43416593563394484\n",
      "Starting epoch 1092 !\n",
      "\n",
      "Loss : 0.451022968405769\n",
      "Starting epoch 1093 !\n",
      "\n",
      "Loss : 0.4544199431429104\n",
      "Starting epoch 1094 !\n",
      "\n",
      "Loss : 0.4594207174923955\n",
      "Starting epoch 1095 !\n",
      "\n",
      "Loss : 0.4794227130153552\n",
      "Starting epoch 1096 !\n",
      "\n",
      "Loss : 0.4676292820447156\n",
      "Starting epoch 1097 !\n",
      "\n",
      "Loss : 0.47007252813196504\n",
      "Starting epoch 1098 !\n",
      "\n",
      "Loss : 0.47269548186842275\n",
      "Starting epoch 1099 !\n",
      "\n",
      "Loss : 0.4595613142057341\n",
      "Starting epoch 1100 !\n",
      "\n",
      "Loss : 0.4579673955837886\n",
      "Starting epoch 1101 !\n",
      "\n",
      "Loss : 0.44245272266621494\n",
      "Starting epoch 1102 !\n",
      "\n",
      "Loss : 0.44241906824160593\n",
      "Starting epoch 1103 !\n",
      "\n",
      "Loss : 0.486745804193474\n",
      "Starting epoch 1104 !\n",
      "\n",
      "Loss : 0.4368007685862431\n",
      "Starting epoch 1105 !\n",
      "\n",
      "Loss : 0.4667953417009237\n",
      "Starting epoch 1106 !\n",
      "\n",
      "Loss : 0.4410586454430405\n",
      "Starting epoch 1107 !\n",
      "\n",
      "Loss : 0.4900030456229943\n",
      "Starting epoch 1108 !\n",
      "\n",
      "Loss : 0.44725864355255956\n",
      "Starting epoch 1109 !\n",
      "\n",
      "Loss : 0.4590056354091281\n",
      "Starting epoch 1110 !\n",
      "\n",
      "Loss : 0.44847962280519965\n",
      "Starting epoch 1111 !\n",
      "\n",
      "Loss : 0.46335063915268904\n",
      "Starting epoch 1112 !\n",
      "\n",
      "Loss : 0.43222219557786473\n",
      "Starting epoch 1113 !\n",
      "\n",
      "Loss : 0.46960978007235493\n",
      "Starting epoch 1114 !\n",
      "\n",
      "Loss : 0.4487610208947642\n",
      "Starting epoch 1115 !\n",
      "\n",
      "Loss : 0.40968782632123857\n",
      "Starting epoch 1116 !\n",
      "\n",
      "Loss : 0.4122558890962276\n",
      "Starting epoch 1117 !\n",
      "\n",
      "Loss : 0.4413390501218588\n",
      "Starting epoch 1118 !\n",
      "\n",
      "Loss : 0.45197058423441283\n",
      "Starting epoch 1119 !\n",
      "\n",
      "Loss : 0.4657854957848179\n",
      "Starting epoch 1120 !\n",
      "\n",
      "Loss : 0.4572845771401918\n",
      "Starting epoch 1121 !\n",
      "\n",
      "Loss : 0.43764885327442976\n",
      "Starting epoch 1122 !\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.4419246619047762\n",
      "Starting epoch 1123 !\n",
      "\n",
      "Loss : 0.42689649953323155\n",
      "Starting epoch 1124 !\n",
      "\n",
      "Loss : 0.4449350626087513\n",
      "Starting epoch 1125 !\n",
      "\n",
      "Loss : 0.4465734961689735\n",
      "Starting epoch 1126 !\n",
      "\n",
      "Loss : 0.46658164607424313\n",
      "Starting epoch 1127 !\n",
      "\n",
      "Loss : 0.4492215857822068\n",
      "Starting epoch 1128 !\n",
      "\n",
      "Loss : 0.43490687793209437\n",
      "Starting epoch 1129 !\n",
      "\n",
      "Loss : 0.43038704585866866\n",
      "Starting epoch 1130 !\n",
      "\n",
      "Loss : 0.4459332940327067\n",
      "Starting epoch 1131 !\n",
      "\n",
      "Loss : 0.4107447083101792\n",
      "Starting epoch 1132 !\n",
      "\n",
      "Loss : 0.45573259347758327\n",
      "Starting epoch 1133 !\n",
      "\n",
      "Loss : 0.45729536770963347\n",
      "Starting epoch 1134 !\n",
      "\n",
      "Loss : 0.46286948207689793\n",
      "Starting epoch 1135 !\n",
      "\n",
      "Loss : 0.43629357867500407\n",
      "Starting epoch 1136 !\n",
      "\n",
      "Loss : 0.4168001284607414\n",
      "Starting epoch 1137 !\n",
      "\n",
      "Loss : 0.4224006998397055\n",
      "Starting epoch 1138 !\n",
      "\n",
      "Loss : 0.40953458936846987\n",
      "Starting epoch 1139 !\n",
      "\n",
      "Loss : 0.4521467480935207\n",
      "Starting epoch 1140 !\n",
      "\n",
      "Loss : 0.4448705679502617\n",
      "Starting epoch 1141 !\n",
      "\n",
      "Loss : 0.43312249996629704\n",
      "Starting epoch 1142 !\n",
      "\n",
      "Loss : 0.4462111110792679\n",
      "Starting epoch 1143 !\n",
      "\n",
      "Loss : 0.44223521933669135\n",
      "Starting epoch 1144 !\n",
      "\n",
      "Loss : 0.4373586595970757\n",
      "Starting epoch 1145 !\n",
      "\n",
      "Loss : 0.4166639845590202\n",
      "Starting epoch 1146 !\n",
      "\n",
      "Loss : 0.44157591350630027\n",
      "Starting epoch 1147 !\n",
      "\n",
      "Loss : 0.4201227807674278\n",
      "Starting epoch 1148 !\n",
      "\n",
      "Loss : 0.4388742505693111\n",
      "Starting epoch 1149 !\n",
      "\n",
      "Loss : 0.42133740208992343\n",
      "Starting epoch 1150 !\n",
      "\n",
      "Loss : 0.43658882374463437\n",
      "Starting epoch 1151 !\n",
      "\n",
      "Loss : 0.42661421416568107\n",
      "Starting epoch 1152 !\n",
      "\n",
      "Loss : 0.43505662456661665\n",
      "Starting epoch 1153 !\n",
      "\n",
      "Loss : 0.4426380530709312\n",
      "Starting epoch 1154 !\n",
      "\n",
      "Loss : 0.4226765011240836\n",
      "Starting epoch 1155 !\n",
      "\n",
      "Loss : 0.42020064744414115\n",
      "Starting epoch 1156 !\n",
      "\n",
      "Loss : 0.4109094778493959\n",
      "Starting epoch 1157 !\n",
      "\n",
      "Loss : 0.4260943137666806\n",
      "Starting epoch 1158 !\n",
      "\n",
      "Loss : 0.4361528951902779\n",
      "Starting epoch 1159 !\n",
      "\n",
      "Loss : 0.426824025607028\n",
      "Starting epoch 1160 !\n",
      "\n",
      "Loss : 0.43275903945877436\n",
      "Starting epoch 1161 !\n",
      "\n",
      "Loss : 0.4186770609852408\n",
      "Starting epoch 1162 !\n",
      "\n",
      "Loss : 0.40829200900736307\n",
      "Starting epoch 1163 !\n",
      "\n",
      "Loss : 0.4102426076016458\n",
      "Starting epoch 1164 !\n",
      "\n",
      "Loss : 0.42983096326086795\n",
      "Starting epoch 1165 !\n",
      "\n",
      "Loss : 0.4404043618614982\n",
      "Starting epoch 1166 !\n",
      "\n",
      "Loss : 0.42416850127735917\n",
      "Starting epoch 1167 !\n",
      "\n",
      "Loss : 0.4313036853156122\n",
      "Starting epoch 1168 !\n",
      "\n",
      "Loss : 0.4426983785467083\n",
      "Starting epoch 1169 !\n",
      "\n",
      "Loss : 0.44279192448878774\n",
      "Starting epoch 1170 !\n",
      "\n",
      "Loss : 0.4264792287532164\n",
      "Starting epoch 1171 !\n",
      "\n",
      "Loss : 0.4428640982123459\n",
      "Starting epoch 1172 !\n",
      "\n",
      "Loss : 0.419438694001866\n",
      "Starting epoch 1173 !\n",
      "\n",
      "Loss : 0.409838863021257\n",
      "Starting epoch 1174 !\n",
      "\n",
      "Loss : 0.38977870750589433\n",
      "Starting epoch 1175 !\n",
      "\n",
      "Loss : 0.4234551822855359\n",
      "Starting epoch 1176 !\n",
      "\n",
      "Loss : 0.4133562654459558\n",
      "Starting epoch 1177 !\n",
      "\n",
      "Loss : 0.4229573382406819\n",
      "Starting epoch 1178 !\n",
      "\n",
      "Loss : 0.46841574840399686\n",
      "Starting epoch 1179 !\n",
      "\n",
      "Loss : 0.41078882715126286\n",
      "Starting epoch 1180 !\n",
      "\n",
      "Loss : 0.4290671853386626\n",
      "Starting epoch 1181 !\n",
      "\n",
      "Loss : 0.4039695569548477\n",
      "Starting epoch 1182 !\n",
      "\n",
      "Loss : 0.40295006588202753\n",
      "Starting epoch 1183 !\n",
      "\n",
      "Loss : 0.41551058843326405\n",
      "Starting epoch 1184 !\n",
      "\n",
      "Loss : 0.42546156712738026\n",
      "Starting epoch 1185 !\n",
      "\n",
      "Loss : 0.3995555508501676\n",
      "Starting epoch 1186 !\n",
      "\n",
      "Loss : 0.4250548255889594\n",
      "Starting epoch 1187 !\n",
      "\n",
      "Loss : 0.41478010479893\n",
      "Starting epoch 1188 !\n",
      "\n",
      "Loss : 0.4157234256973072\n",
      "Starting epoch 1189 !\n",
      "\n",
      "Loss : 0.41022413705481964\n",
      "Starting epoch 1190 !\n",
      "\n",
      "Loss : 0.40021817087113454\n",
      "Starting epoch 1191 !\n",
      "\n",
      "Loss : 0.41887241855365076\n",
      "Starting epoch 1192 !\n",
      "\n",
      "Loss : 0.41281495963026876\n",
      "Starting epoch 1193 !\n",
      "\n",
      "Loss : 0.424748944587448\n",
      "Starting epoch 1194 !\n",
      "\n",
      "Loss : 0.41432791005591957\n",
      "Starting epoch 1195 !\n",
      "\n",
      "Loss : 0.4129337578707812\n",
      "Starting epoch 1196 !\n",
      "\n",
      "Loss : 0.3833098081098933\n",
      "Starting epoch 1197 !\n",
      "\n",
      "Loss : 0.4000033743324734\n",
      "Starting epoch 1198 !\n",
      "\n",
      "Loss : 0.40109116558720465\n",
      "Starting epoch 1199 !\n",
      "\n",
      "Loss : 0.39279880739596423\n",
      "Starting epoch 1200 !\n",
      "\n",
      "Loss : 0.41110035478055074\n",
      "Starting epoch 1201 !\n",
      "\n",
      "Loss : 0.41978554321186884\n",
      "Starting epoch 1202 !\n",
      "\n",
      "Loss : 0.4103733659500167\n",
      "Starting epoch 1203 !\n",
      "\n",
      "Loss : 0.40081391650803233\n",
      "Starting epoch 1204 !\n",
      "\n",
      "Loss : 0.4193737494702242\n",
      "Starting epoch 1205 !\n",
      "\n",
      "Loss : 0.39872126007566644\n",
      "Starting epoch 1206 !\n",
      "\n",
      "Loss : 0.404227307205703\n",
      "Starting epoch 1207 !\n",
      "\n",
      "Loss : 0.3957835412552568\n",
      "Starting epoch 1208 !\n",
      "\n",
      "Loss : 0.42214522895967066\n",
      "Starting epoch 1209 !\n",
      "\n",
      "Loss : 0.43174659668588317\n",
      "Starting epoch 1210 !\n",
      "\n",
      "Loss : 0.4246084694655574\n",
      "Starting epoch 1211 !\n",
      "\n",
      "Loss : 0.41941912421563854\n",
      "Starting epoch 1212 !\n",
      "\n",
      "Loss : 0.40943420693582416\n",
      "Starting epoch 1213 !\n",
      "\n",
      "Loss : 0.4263409226625955\n",
      "Starting epoch 1214 !\n",
      "\n",
      "Loss : 0.39481189198234456\n",
      "Starting epoch 1215 !\n",
      "\n",
      "Loss : 0.4051223307037029\n",
      "Starting epoch 1216 !\n",
      "\n",
      "Loss : 0.42498444897585175\n",
      "Starting epoch 1217 !\n",
      "\n",
      "Loss : 0.4332283457018891\n",
      "Starting epoch 1218 !\n",
      "\n",
      "Loss : 0.41411530049074263\n",
      "Starting epoch 1219 !\n",
      "\n",
      "Loss : 0.38175686869491526\n",
      "Starting epoch 1220 !\n",
      "\n",
      "Loss : 0.4121431551721631\n",
      "Starting epoch 1221 !\n",
      "\n",
      "Loss : 0.403294091524721\n",
      "Starting epoch 1222 !\n",
      "\n",
      "Loss : 0.4083053590286346\n",
      "Starting epoch 1223 !\n",
      "\n",
      "Loss : 0.3992366167862399\n",
      "Starting epoch 1224 !\n",
      "\n",
      "Loss : 0.40934760746907217\n",
      "Starting epoch 1225 !\n",
      "\n",
      "Loss : 0.40374138626922557\n",
      "Starting epoch 1226 !\n",
      "\n",
      "Loss : 0.4113410175556228\n",
      "Starting epoch 1227 !\n",
      "\n",
      "Loss : 0.3837536463425273\n",
      "Starting epoch 1228 !\n",
      "\n",
      "Loss : 0.3913411856914053\n",
      "Starting epoch 1229 !\n",
      "\n",
      "Loss : 0.3963446079366872\n",
      "Starting epoch 1230 !\n",
      "\n",
      "Loss : 0.40018955643485193\n",
      "Starting epoch 1231 !\n",
      "\n",
      "Loss : 0.3934581622379978\n",
      "Starting epoch 1232 !\n",
      "\n",
      "Loss : 0.39643045854406295\n",
      "Starting epoch 1233 !\n",
      "\n",
      "Loss : 0.3834721837319484\n",
      "Starting epoch 1234 !\n",
      "\n",
      "Loss : 0.3842797540381652\n",
      "Starting epoch 1235 !\n",
      "\n",
      "Loss : 0.40544916983364393\n",
      "Starting epoch 1236 !\n",
      "\n",
      "Loss : 0.40993397105105067\n",
      "Starting epoch 1237 !\n",
      "\n",
      "Loss : 0.3924629711577681\n",
      "Starting epoch 1238 !\n",
      "\n",
      "Loss : 0.40247443419735446\n",
      "Starting epoch 1239 !\n",
      "\n",
      "Loss : 0.40424379437756375\n",
      "Starting epoch 1240 !\n",
      "\n",
      "Loss : 0.406023798447077\n",
      "Starting epoch 1241 !\n",
      "\n",
      "Loss : 0.4087772190469463\n",
      "Starting epoch 1242 !\n",
      "\n",
      "Loss : 0.38861938023648296\n",
      "Starting epoch 1243 !\n",
      "\n",
      "Loss : 0.4002937714056093\n",
      "Starting epoch 1244 !\n",
      "\n",
      "Loss : 0.38058980589821223\n",
      "Starting epoch 1245 !\n",
      "\n",
      "Loss : 0.38124946459215514\n",
      "Starting epoch 1246 !\n",
      "\n",
      "Loss : 0.39052479034986626\n",
      "Starting epoch 1247 !\n",
      "\n",
      "Loss : 0.3913997475590025\n",
      "Starting epoch 1248 !\n",
      "\n",
      "Loss : 0.4098104471657552\n",
      "Starting epoch 1249 !\n",
      "\n",
      "Loss : 0.3928574789949015\n",
      "Starting epoch 1250 !\n",
      "\n",
      "Loss : 0.3705225042035791\n",
      "Starting epoch 1251 !\n",
      "\n",
      "Loss : 0.38440541461819694\n",
      "Starting epoch 1252 !\n",
      "\n",
      "Loss : 0.3915426242006879\n",
      "Starting epoch 1253 !\n",
      "\n",
      "Loss : 0.3622688621688051\n",
      "Starting epoch 1254 !\n",
      "\n",
      "Loss : 0.4154217412479881\n",
      "Starting epoch 1255 !\n",
      "\n",
      "Loss : 0.384980891432081\n",
      "Starting epoch 1256 !\n",
      "\n",
      "Loss : 0.4322576929821449\n",
      "Starting epoch 1257 !\n",
      "\n",
      "Loss : 0.39105290640779095\n",
      "Starting epoch 1258 !\n",
      "\n",
      "Loss : 0.402197609294434\n",
      "Starting epoch 1259 !\n",
      "\n",
      "Loss : 0.41426915153354205\n",
      "Starting epoch 1260 !\n",
      "\n",
      "Loss : 0.3991026967054322\n",
      "Starting epoch 1261 !\n",
      "\n",
      "Loss : 0.375512293356211\n",
      "Starting epoch 1262 !\n",
      "\n",
      "Loss : 0.3721130159841914\n",
      "Starting epoch 1263 !\n",
      "\n",
      "Loss : 0.3842204891297282\n",
      "Starting epoch 1264 !\n",
      "\n",
      "Loss : 0.38799209771107657\n",
      "Starting epoch 1265 !\n",
      "\n",
      "Loss : 0.4003769386889172\n",
      "Starting epoch 1266 !\n",
      "\n",
      "Loss : 0.3859617709606683\n",
      "Starting epoch 1267 !\n",
      "\n",
      "Loss : 0.3858045469842801\n",
      "Starting epoch 1268 !\n",
      "\n",
      "Loss : 0.38344359053235477\n",
      "Starting epoch 1269 !\n",
      "\n",
      "Loss : 0.3972990721666894\n",
      "Starting epoch 1270 !\n",
      "\n",
      "Loss : 0.3880579411780753\n",
      "Starting epoch 1271 !\n",
      "\n",
      "Loss : 0.36974012679388735\n",
      "Starting epoch 1272 !\n",
      "\n",
      "Loss : 0.3839690119636302\n",
      "Starting epoch 1273 !\n",
      "\n",
      "Loss : 0.38601398133501713\n",
      "Starting epoch 1274 !\n",
      "\n",
      "Loss : 0.3877187137092863\n",
      "Starting epoch 1275 !\n",
      "\n",
      "Loss : 0.3723879233509505\n",
      "Starting epoch 1276 !\n",
      "\n",
      "Loss : 0.37515693218732366\n",
      "Starting epoch 1277 !\n",
      "\n",
      "Loss : 0.3865494224794057\n",
      "Starting epoch 1278 !\n",
      "\n",
      "Loss : 0.36784287227862544\n",
      "Starting epoch 1279 !\n",
      "\n",
      "Loss : 0.3709430757935355\n",
      "Starting epoch 1280 !\n",
      "\n",
      "Loss : 0.38224982571642413\n",
      "Starting epoch 1281 !\n",
      "\n",
      "Loss : 0.37857463494652793\n",
      "Starting epoch 1282 !\n",
      "\n",
      "Loss : 0.37172468746600507\n",
      "Starting epoch 1283 !\n",
      "\n",
      "Loss : 0.3803331634017075\n",
      "Starting epoch 1284 !\n",
      "\n",
      "Loss : 0.4029918370806441\n",
      "Starting epoch 1285 !\n",
      "\n",
      "Loss : 0.3881083862716649\n",
      "Starting epoch 1286 !\n",
      "\n",
      "Loss : 0.3695783952162379\n",
      "Starting epoch 1287 !\n",
      "\n",
      "Loss : 0.37101838043352375\n",
      "Starting epoch 1288 !\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.3618179008263309\n",
      "Starting epoch 1289 !\n",
      "\n",
      "Loss : 0.38286317084111327\n",
      "Starting epoch 1290 !\n",
      "\n",
      "Loss : 0.3812312063108496\n",
      "Starting epoch 1291 !\n",
      "\n",
      "Loss : 0.36128804270102055\n",
      "Starting epoch 1292 !\n",
      "\n",
      "Loss : 0.39040897330459284\n",
      "Starting epoch 1293 !\n",
      "\n",
      "Loss : 0.3780036634531151\n",
      "Starting epoch 1294 !\n",
      "\n",
      "Loss : 0.3716204382327138\n",
      "Starting epoch 1295 !\n",
      "\n",
      "Loss : 0.3246467129206982\n",
      "Starting epoch 1296 !\n",
      "\n",
      "Loss : 0.35869326695901194\n",
      "Starting epoch 1297 !\n",
      "\n",
      "Loss : 0.3787984922528267\n",
      "Starting epoch 1298 !\n",
      "\n",
      "Loss : 0.3821662509826576\n",
      "Starting epoch 1299 !\n",
      "\n",
      "Loss : 0.3593366388358226\n",
      "Starting epoch 1300 !\n",
      "\n",
      "Loss : 0.3822185557310273\n",
      "Starting epoch 1301 !\n",
      "\n",
      "Loss : 0.3685501353168974\n",
      "Starting epoch 1302 !\n",
      "\n",
      "Loss : 0.3760151812920765\n",
      "Starting epoch 1303 !\n",
      "\n",
      "Loss : 0.37007982593004396\n",
      "Starting epoch 1304 !\n",
      "\n",
      "Loss : 0.38248811124944365\n",
      "Starting epoch 1305 !\n",
      "\n",
      "Loss : 0.3870775050350598\n",
      "Starting epoch 1306 !\n",
      "\n",
      "Loss : 0.40723104055235987\n",
      "Starting epoch 1307 !\n",
      "\n",
      "Loss : 0.38750581352078184\n",
      "Starting epoch 1308 !\n",
      "\n",
      "Loss : 0.3834483139470321\n",
      "Starting epoch 1309 !\n",
      "\n",
      "Loss : 0.37821208579199656\n",
      "Starting epoch 1310 !\n",
      "\n",
      "Loss : 0.3704543926683413\n",
      "Starting epoch 1311 !\n",
      "\n",
      "Loss : 0.35336658338300225\n",
      "Starting epoch 1312 !\n",
      "\n",
      "Loss : 0.3707940760923892\n",
      "Starting epoch 1313 !\n",
      "\n",
      "Loss : 0.37142877275643704\n",
      "Starting epoch 1314 !\n",
      "\n",
      "Loss : 0.3571534335714619\n",
      "Starting epoch 1315 !\n",
      "\n",
      "Loss : 0.3661504115681259\n",
      "Starting epoch 1316 !\n",
      "\n",
      "Loss : 0.3706250661084441\n",
      "Starting epoch 1317 !\n",
      "\n",
      "Loss : 0.3737010911715274\n",
      "Starting epoch 1318 !\n",
      "\n",
      "Loss : 0.3769017053501947\n",
      "Starting epoch 1319 !\n",
      "\n",
      "Loss : 0.3704709057905236\n",
      "Starting epoch 1320 !\n",
      "\n",
      "Loss : 0.3435794562101364\n",
      "Starting epoch 1321 !\n",
      "\n",
      "Loss : 0.3379941881209815\n",
      "Starting epoch 1322 !\n",
      "\n",
      "Loss : 0.3614932162826564\n",
      "Starting epoch 1323 !\n",
      "\n",
      "Loss : 0.35588424815004377\n",
      "Starting epoch 1324 !\n",
      "\n",
      "Loss : 0.3605827396216036\n",
      "Starting epoch 1325 !\n",
      "\n",
      "Loss : 0.3633537482039458\n",
      "Starting epoch 1326 !\n",
      "\n",
      "Loss : 0.3614493262301497\n",
      "Starting epoch 1327 !\n",
      "\n",
      "Loss : 0.3469432223410833\n",
      "Starting epoch 1328 !\n",
      "\n",
      "Loss : 0.3782913746172879\n",
      "Starting epoch 1329 !\n",
      "\n",
      "Loss : 0.3730823135092145\n",
      "Starting epoch 1330 !\n",
      "\n",
      "Loss : 0.3854769915342331\n",
      "Starting epoch 1331 !\n",
      "\n",
      "Loss : 0.34989866938720754\n",
      "Starting epoch 1332 !\n",
      "\n",
      "Loss : 0.3443408789886098\n",
      "Starting epoch 1333 !\n",
      "\n",
      "Loss : 0.36263557939099617\n",
      "Starting epoch 1334 !\n",
      "\n",
      "Loss : 0.37732494480553125\n",
      "Starting epoch 1335 !\n",
      "\n",
      "Loss : 0.3704861326992106\n",
      "Starting epoch 1336 !\n",
      "\n",
      "Loss : 0.3525716880349075\n",
      "Starting epoch 1337 !\n",
      "\n",
      "Loss : 0.36113460027441685\n",
      "Starting epoch 1338 !\n",
      "\n",
      "Loss : 0.371365192491992\n",
      "Starting epoch 1339 !\n",
      "\n",
      "Loss : 0.3581359673316787\n",
      "Starting epoch 1340 !\n",
      "\n",
      "Loss : 0.3692765063067683\n",
      "Starting epoch 1341 !\n",
      "\n",
      "Loss : 0.3514921405181593\n",
      "Starting epoch 1342 !\n",
      "\n",
      "Loss : 0.36846070579525564\n",
      "Starting epoch 1343 !\n",
      "\n",
      "Loss : 0.35758836780275616\n",
      "Starting epoch 1344 !\n",
      "\n",
      "Loss : 0.341824055731702\n",
      "Starting epoch 1345 !\n",
      "\n",
      "Loss : 0.36036929158734626\n",
      "Starting epoch 1346 !\n",
      "\n",
      "Loss : 0.35540982315532205\n",
      "Starting epoch 1347 !\n",
      "\n",
      "Loss : 0.3520501807433407\n",
      "Starting epoch 1348 !\n",
      "\n",
      "Loss : 0.36117708353566474\n",
      "Starting epoch 1349 !\n",
      "\n",
      "Loss : 0.35166588902067974\n",
      "Starting epoch 1350 !\n",
      "\n",
      "Loss : 0.3554673209583678\n",
      "Starting epoch 1351 !\n",
      "\n",
      "Loss : 0.33551604123342604\n",
      "Starting epoch 1352 !\n",
      "\n",
      "Loss : 0.3303902071146738\n",
      "Starting epoch 1353 !\n",
      "\n",
      "Loss : 0.3592942795735233\n",
      "Starting epoch 1354 !\n",
      "\n",
      "Loss : 0.35331287782411186\n",
      "Starting epoch 1355 !\n",
      "\n",
      "Loss : 0.3437308428340218\n",
      "Starting epoch 1356 !\n",
      "\n",
      "Loss : 0.3504219693290133\n",
      "Starting epoch 1357 !\n",
      "\n",
      "Loss : 0.35432918466070074\n",
      "Starting epoch 1358 !\n",
      "\n",
      "Loss : 0.3360103667796064\n",
      "Starting epoch 1359 !\n",
      "\n",
      "Loss : 0.3417646645181844\n",
      "Starting epoch 1360 !\n",
      "\n",
      "Loss : 0.3496015117484696\n",
      "Starting epoch 1361 !\n",
      "\n",
      "Loss : 0.34251279530882023\n",
      "Starting epoch 1362 !\n",
      "\n",
      "Loss : 0.3657445787471168\n",
      "Starting epoch 1363 !\n",
      "\n",
      "Loss : 0.35744258411684815\n",
      "Starting epoch 1364 !\n",
      "\n",
      "Loss : 0.3458414303810418\n",
      "Starting epoch 1365 !\n",
      "\n",
      "Loss : 0.34100136105097884\n",
      "Starting epoch 1366 !\n",
      "\n",
      "Loss : 0.3292604511996516\n",
      "Starting epoch 1367 !\n",
      "\n",
      "Loss : 0.31099869265240065\n",
      "Starting epoch 1368 !\n",
      "\n",
      "Loss : 0.3396639337851888\n",
      "Starting epoch 1369 !\n",
      "\n",
      "Loss : 0.3436366291019787\n",
      "Starting epoch 1370 !\n",
      "\n",
      "Loss : 0.33743491540757975\n",
      "Starting epoch 1371 !\n",
      "\n",
      "Loss : 0.3478508933263571\n",
      "Starting epoch 1372 !\n",
      "\n",
      "Loss : 0.3594597702225049\n",
      "Starting epoch 1373 !\n",
      "\n",
      "Loss : 0.35981676980954447\n",
      "Starting epoch 1374 !\n",
      "\n",
      "Loss : 0.34842816451374364\n",
      "Starting epoch 1375 !\n",
      "\n",
      "Loss : 0.3417563546879762\n",
      "Starting epoch 1376 !\n",
      "\n",
      "Loss : 0.33052826459918705\n",
      "Starting epoch 1377 !\n",
      "\n",
      "Loss : 0.348080421183385\n",
      "Starting epoch 1378 !\n",
      "\n",
      "Loss : 0.3321270352723647\n",
      "Starting epoch 1379 !\n",
      "\n",
      "Loss : 0.34714771548704226\n",
      "Starting epoch 1380 !\n",
      "\n",
      "Loss : 0.34982854087336535\n",
      "Starting epoch 1381 !\n",
      "\n",
      "Loss : 0.3657752330712721\n",
      "Starting epoch 1382 !\n",
      "\n",
      "Loss : 0.3541569319002482\n",
      "Starting epoch 1383 !\n",
      "\n",
      "Loss : 0.33357834126673586\n",
      "Starting epoch 1384 !\n",
      "\n",
      "Loss : 0.33988131273563216\n",
      "Starting epoch 1385 !\n",
      "\n",
      "Loss : 0.32415656111881036\n",
      "Starting epoch 1386 !\n",
      "\n",
      "Loss : 0.3498429442648174\n",
      "Starting epoch 1387 !\n",
      "\n",
      "Loss : 0.3505139085305791\n",
      "Starting epoch 1388 !\n",
      "\n",
      "Loss : 0.3532758692697603\n",
      "Starting epoch 1389 !\n",
      "\n",
      "Loss : 0.3121359622498759\n",
      "Starting epoch 1390 !\n",
      "\n",
      "Loss : 0.3485777489587563\n",
      "Starting epoch 1391 !\n",
      "\n",
      "Loss : 0.3377346288995678\n",
      "Starting epoch 1392 !\n",
      "\n",
      "Loss : 0.32233642614414904\n",
      "Starting epoch 1393 !\n",
      "\n",
      "Loss : 0.3240649584097927\n",
      "Starting epoch 1394 !\n",
      "\n",
      "Loss : 0.36091098848248826\n",
      "Starting epoch 1395 !\n",
      "\n",
      "Loss : 0.32879766558303314\n",
      "Starting epoch 1396 !\n",
      "\n",
      "Loss : 0.32512962742119417\n",
      "Starting epoch 1397 !\n",
      "\n",
      "Loss : 0.33529704834530955\n",
      "Starting epoch 1398 !\n",
      "\n",
      "Loss : 0.33082255371371094\n",
      "Starting epoch 1399 !\n",
      "\n",
      "Loss : 0.3361830368739407\n",
      "Starting epoch 1400 !\n",
      "\n",
      "Loss : 0.33994705346571347\n",
      "Starting epoch 1401 !\n",
      "\n",
      "Loss : 0.34484980382075925\n",
      "Starting epoch 1402 !\n",
      "\n",
      "Loss : 0.33812911813559177\n",
      "Starting epoch 1403 !\n",
      "\n",
      "Loss : 0.3104397504001248\n",
      "Starting epoch 1404 !\n",
      "\n",
      "Loss : 0.34173554288489477\n",
      "Starting epoch 1405 !\n",
      "\n",
      "Loss : 0.313697911342796\n",
      "Starting epoch 1406 !\n",
      "\n",
      "Loss : 0.3207094347497233\n",
      "Starting epoch 1407 !\n",
      "\n",
      "Loss : 0.34111701737658506\n",
      "Starting epoch 1408 !\n",
      "\n",
      "Loss : 0.33628032072668984\n",
      "Starting epoch 1409 !\n",
      "\n",
      "Loss : 0.3183566526490815\n",
      "Starting epoch 1410 !\n",
      "\n",
      "Loss : 0.3326893497993346\n",
      "Starting epoch 1411 !\n",
      "\n",
      "Loss : 0.34802594339969206\n",
      "Starting epoch 1412 !\n",
      "\n",
      "Loss : 0.34644694170173335\n",
      "Starting epoch 1413 !\n",
      "\n",
      "Loss : 0.33320246053998975\n",
      "Starting epoch 1414 !\n",
      "\n",
      "Loss : 0.3340348327139608\n",
      "Starting epoch 1415 !\n",
      "\n",
      "Loss : 0.3541695180596138\n",
      "Starting epoch 1416 !\n",
      "\n",
      "Loss : 0.31502306471471075\n",
      "Starting epoch 1417 !\n",
      "\n",
      "Loss : 0.34080103364120534\n",
      "Starting epoch 1418 !\n",
      "\n",
      "Loss : 0.33025875038841146\n",
      "Starting epoch 1419 !\n",
      "\n",
      "Loss : 0.3413293363691187\n",
      "Starting epoch 1420 !\n",
      "\n",
      "Loss : 0.3508717694452831\n",
      "Starting epoch 1421 !\n",
      "\n",
      "Loss : 0.3377436566717771\n",
      "Starting epoch 1422 !\n",
      "\n",
      "Loss : 0.3286832561399661\n",
      "Starting epoch 1423 !\n",
      "\n",
      "Loss : 0.3061314551096384\n",
      "Starting epoch 1424 !\n",
      "\n",
      "Loss : 0.33099039927834556\n",
      "Starting epoch 1425 !\n",
      "\n",
      "Loss : 0.3226655920346578\n",
      "Starting epoch 1426 !\n",
      "\n",
      "Loss : 0.33120703661725637\n",
      "Starting epoch 1427 !\n",
      "\n",
      "Loss : 0.320070565963278\n",
      "Starting epoch 1428 !\n",
      "\n",
      "Loss : 0.30827730004580656\n",
      "Starting epoch 1429 !\n",
      "\n",
      "Loss : 0.3394088605735578\n",
      "Starting epoch 1430 !\n",
      "\n",
      "Loss : 0.33278607860917137\n",
      "Starting epoch 1431 !\n",
      "\n",
      "Loss : 0.3329379630534827\n",
      "Starting epoch 1432 !\n",
      "\n",
      "Loss : 0.31727536554847446\n",
      "Starting epoch 1433 !\n",
      "\n",
      "Loss : 0.3220926364567004\n",
      "Starting epoch 1434 !\n",
      "\n",
      "Loss : 0.3164716139435768\n",
      "Starting epoch 1435 !\n",
      "\n",
      "Loss : 0.325897978834149\n",
      "Starting epoch 1436 !\n",
      "\n",
      "Loss : 0.30792592187114315\n",
      "Starting epoch 1437 !\n",
      "\n",
      "Loss : 0.3230255368818231\n",
      "Starting epoch 1438 !\n",
      "\n",
      "Loss : 0.3496335625749867\n",
      "Starting epoch 1439 !\n",
      "\n",
      "Loss : 0.31863784252786315\n",
      "Starting epoch 1440 !\n",
      "\n",
      "Loss : 0.3110712206586689\n",
      "Starting epoch 1441 !\n",
      "\n",
      "Loss : 0.3253490124024501\n",
      "Starting epoch 1442 !\n",
      "\n",
      "Loss : 0.32401590028993127\n",
      "Starting epoch 1443 !\n",
      "\n",
      "Loss : 0.3192461170509559\n",
      "Starting epoch 1444 !\n",
      "\n",
      "Loss : 0.33036654848022523\n",
      "Starting epoch 1445 !\n",
      "\n",
      "Loss : 0.33594422541609426\n",
      "Starting epoch 1446 !\n",
      "\n",
      "Loss : 0.3349434478956015\n",
      "Starting epoch 1447 !\n",
      "\n",
      "Loss : 0.33186799951759327\n",
      "Starting epoch 1448 !\n",
      "\n",
      "Loss : 0.2985628068345745\n",
      "Starting epoch 1449 !\n",
      "\n",
      "Loss : 0.348044291138649\n",
      "Starting epoch 1450 !\n",
      "\n",
      "Loss : 0.32036030312784675\n",
      "Starting epoch 1451 !\n",
      "\n",
      "Loss : 0.31524515304030204\n",
      "Starting epoch 1452 !\n",
      "\n",
      "Loss : 0.30912756960408216\n",
      "Starting epoch 1453 !\n",
      "\n",
      "Loss : 0.32952977640896425\n",
      "Starting epoch 1454 !\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.3302072312454788\n",
      "Starting epoch 1455 !\n",
      "\n",
      "Loss : 0.31000284516081517\n",
      "Starting epoch 1456 !\n",
      "\n",
      "Loss : 0.3231293506362811\n",
      "Starting epoch 1457 !\n",
      "\n",
      "Loss : 0.3265129803192048\n",
      "Starting epoch 1458 !\n",
      "\n",
      "Loss : 0.3103939559893543\n",
      "Starting epoch 1459 !\n",
      "\n",
      "Loss : 0.320852150316952\n",
      "Starting epoch 1460 !\n",
      "\n",
      "Loss : 0.3144619105016293\n",
      "Starting epoch 1461 !\n",
      "\n",
      "Loss : 0.31353114758219036\n",
      "Starting epoch 1462 !\n",
      "\n",
      "Loss : 0.33511662047331026\n",
      "Starting epoch 1463 !\n",
      "\n",
      "Loss : 0.3316678420520153\n",
      "Starting epoch 1464 !\n",
      "\n",
      "Loss : 0.31946558231601907\n",
      "Starting epoch 1465 !\n",
      "\n",
      "Loss : 0.31132481556360414\n",
      "Starting epoch 1466 !\n",
      "\n",
      "Loss : 0.305146630726704\n",
      "Starting epoch 1467 !\n",
      "\n",
      "Loss : 0.3169097017218061\n",
      "Starting epoch 1468 !\n",
      "\n",
      "Loss : 0.3258873347421082\n",
      "Starting epoch 1469 !\n",
      "\n",
      "Loss : 0.31728439879457965\n",
      "Starting epoch 1470 !\n",
      "\n",
      "Loss : 0.34219101192999857\n",
      "Starting epoch 1471 !\n",
      "\n",
      "Loss : 0.31453570084912436\n",
      "Starting epoch 1472 !\n",
      "\n",
      "Loss : 0.3148994311994436\n",
      "Starting epoch 1473 !\n",
      "\n",
      "Loss : 0.32436025953617226\n",
      "Starting epoch 1474 !\n",
      "\n",
      "Loss : 0.32047340527278223\n",
      "Starting epoch 1475 !\n",
      "\n",
      "Loss : 0.3037846694592716\n",
      "Starting epoch 1476 !\n",
      "\n",
      "Loss : 0.3092209612127064\n",
      "Starting epoch 1477 !\n",
      "\n",
      "Loss : 0.2883369073170383\n",
      "Starting epoch 1478 !\n",
      "\n",
      "Loss : 0.30994224669981973\n",
      "Starting epoch 1479 !\n",
      "\n",
      "Loss : 0.30907410008161246\n",
      "Starting epoch 1480 !\n",
      "\n",
      "Loss : 0.3179860856561434\n",
      "Starting epoch 1481 !\n",
      "\n",
      "Loss : 0.3302311384353508\n",
      "Starting epoch 1482 !\n",
      "\n",
      "Loss : 0.3117531661679145\n",
      "Starting epoch 1483 !\n",
      "\n",
      "Loss : 0.32459344745290525\n",
      "Starting epoch 1484 !\n",
      "\n",
      "Loss : 0.3361620367789755\n",
      "Starting epoch 1485 !\n",
      "\n",
      "Loss : 0.30340855715631626\n",
      "Starting epoch 1486 !\n",
      "\n",
      "Loss : 0.30821450120535027\n",
      "Starting epoch 1487 !\n",
      "\n",
      "Loss : 0.31432210273888644\n",
      "Starting epoch 1488 !\n",
      "\n",
      "Loss : 0.3243764599873906\n",
      "Starting epoch 1489 !\n",
      "\n",
      "Loss : 0.2873574145594422\n",
      "Starting epoch 1490 !\n",
      "\n",
      "Loss : 0.31748588362924096\n",
      "Starting epoch 1491 !\n",
      "\n",
      "Loss : 0.31652228088200496\n",
      "Starting epoch 1492 !\n",
      "\n",
      "Loss : 0.31945595981515185\n",
      "Starting epoch 1493 !\n",
      "\n",
      "Loss : 0.30361536373289266\n",
      "Starting epoch 1494 !\n",
      "\n",
      "Loss : 0.3031258213834292\n",
      "Starting epoch 1495 !\n",
      "\n",
      "Loss : 0.2976339381872391\n",
      "Starting epoch 1496 !\n",
      "\n",
      "Loss : 0.3182138176698263\n",
      "Starting epoch 1497 !\n",
      "\n",
      "Loss : 0.315391264247651\n",
      "Starting epoch 1498 !\n",
      "\n",
      "Loss : 0.2884673906021378\n",
      "Starting epoch 1499 !\n",
      "\n",
      "Loss : 0.30449182038404504\n",
      "Starting epoch 1500 !\n",
      "\n",
      "Loss : 0.3025616281697539\n",
      "Starting epoch 1501 !\n",
      "\n",
      "Loss : 0.30975220271316517\n",
      "Starting epoch 1502 !\n",
      "\n",
      "Loss : 0.30108457768247243\n",
      "Starting epoch 1503 !\n",
      "\n",
      "Loss : 0.30983888023361866\n",
      "Starting epoch 1504 !\n",
      "\n",
      "Loss : 0.3009054864040848\n",
      "Starting epoch 1505 !\n",
      "\n",
      "Loss : 0.29409190241982336\n",
      "Starting epoch 1506 !\n",
      "\n",
      "Loss : 0.3197753060431707\n",
      "Starting epoch 1507 !\n",
      "\n",
      "Loss : 0.3204467303696133\n",
      "Starting epoch 1508 !\n",
      "\n",
      "Loss : 0.2815463145827355\n",
      "Starting epoch 1509 !\n",
      "\n",
      "Loss : 0.29577536840422625\n",
      "Starting epoch 1510 !\n",
      "\n",
      "Loss : 0.3002841649513666\n",
      "Starting epoch 1511 !\n",
      "\n",
      "Loss : 0.30534175940516856\n",
      "Starting epoch 1512 !\n",
      "\n",
      "Loss : 0.32851894387379793\n",
      "Starting epoch 1513 !\n",
      "\n",
      "Loss : 0.3127142904060228\n",
      "Starting epoch 1514 !\n",
      "\n",
      "Loss : 0.3145374597943559\n",
      "Starting epoch 1515 !\n",
      "\n",
      "Loss : 0.30402518580762705\n",
      "Starting epoch 1516 !\n",
      "\n",
      "Loss : 0.31425924806975997\n",
      "Starting epoch 1517 !\n",
      "\n",
      "Loss : 0.3031957988329485\n",
      "Starting epoch 1518 !\n",
      "\n",
      "Loss : 0.280821189132272\n",
      "Starting epoch 1519 !\n",
      "\n",
      "Loss : 0.302717124827865\n",
      "Starting epoch 1520 !\n",
      "\n",
      "Loss : 0.29110521691388824\n",
      "Starting epoch 1521 !\n",
      "\n",
      "Loss : 0.29933162248965833\n",
      "Starting epoch 1522 !\n",
      "\n",
      "Loss : 0.3013262726163783\n",
      "Starting epoch 1523 !\n",
      "\n",
      "Loss : 0.3093958922288045\n",
      "Starting epoch 1524 !\n",
      "\n",
      "Loss : 0.28562371067854825\n",
      "Starting epoch 1525 !\n",
      "\n",
      "Loss : 0.2954155435012717\n",
      "Starting epoch 1526 !\n",
      "\n",
      "Loss : 0.30749731009103815\n",
      "Starting epoch 1527 !\n",
      "\n",
      "Loss : 0.2895806989296764\n",
      "Starting epoch 1528 !\n",
      "\n",
      "Loss : 0.2959776701418316\n",
      "Starting epoch 1529 !\n",
      "\n",
      "Loss : 0.293691841771408\n",
      "Starting epoch 1530 !\n",
      "\n",
      "Loss : 0.29965909768124016\n",
      "Starting epoch 1531 !\n",
      "\n",
      "Loss : 0.3022194936060581\n",
      "Starting epoch 1532 !\n",
      "\n",
      "Loss : 0.29727078213983654\n",
      "Starting epoch 1533 !\n",
      "\n",
      "Loss : 0.3208613018093466\n",
      "Starting epoch 1534 !\n",
      "\n",
      "Loss : 0.28749429353443134\n",
      "Starting epoch 1535 !\n",
      "\n",
      "Loss : 0.2977493656735842\n",
      "Starting epoch 1536 !\n",
      "\n",
      "Loss : 0.2970929835625246\n",
      "Starting epoch 1537 !\n",
      "\n",
      "Loss : 0.3002790421196798\n",
      "Starting epoch 1538 !\n",
      "\n",
      "Loss : 0.3051259066580104\n",
      "Starting epoch 1539 !\n",
      "\n",
      "Loss : 0.3126934131696111\n",
      "Starting epoch 1540 !\n",
      "\n",
      "Loss : 0.30994209946215556\n",
      "Starting epoch 1541 !\n",
      "\n",
      "Loss : 0.2960955339933739\n",
      "Starting epoch 1542 !\n",
      "\n",
      "Loss : 0.2970606585850521\n",
      "Starting epoch 1543 !\n",
      "\n",
      "Loss : 0.29127505654785907\n",
      "Starting epoch 1544 !\n",
      "\n",
      "Loss : 0.27007208511131964\n",
      "Starting epoch 1545 !\n",
      "\n",
      "Loss : 0.2988270954514036\n",
      "Starting epoch 1546 !\n",
      "\n",
      "Loss : 0.3016802696701215\n",
      "Starting epoch 1547 !\n",
      "\n",
      "Loss : 0.2904646324158526\n",
      "Starting epoch 1548 !\n",
      "\n",
      "Loss : 0.31111540133450305\n",
      "Starting epoch 1549 !\n",
      "\n",
      "Loss : 0.30832159118790203\n",
      "Starting epoch 1550 !\n",
      "\n",
      "Loss : 0.2922177012173497\n",
      "Starting epoch 1551 !\n",
      "\n",
      "Loss : 0.2949361569773989\n",
      "Starting epoch 1552 !\n",
      "\n",
      "Loss : 0.29101517036253094\n",
      "Starting epoch 1553 !\n",
      "\n",
      "Loss : 0.28244958235090284\n",
      "Starting epoch 1554 !\n",
      "\n",
      "Loss : 0.3024106412416413\n",
      "Starting epoch 1555 !\n",
      "\n",
      "Loss : 0.31481348175783547\n",
      "Starting epoch 1556 !\n",
      "\n",
      "Loss : 0.2899797026093314\n",
      "Starting epoch 1557 !\n",
      "\n",
      "Loss : 0.28638497010177494\n",
      "Starting epoch 1558 !\n",
      "\n",
      "Loss : 0.294826323027108\n",
      "Starting epoch 1559 !\n",
      "\n",
      "Loss : 0.2823066408587556\n",
      "Starting epoch 1560 !\n",
      "\n",
      "Loss : 0.27820231613455987\n",
      "Starting epoch 1561 !\n",
      "\n",
      "Loss : 0.2866049168669448\n",
      "Starting epoch 1562 !\n",
      "\n",
      "Loss : 0.2876918789024661\n",
      "Starting epoch 1563 !\n",
      "\n",
      "Loss : 0.2789021246388656\n",
      "Starting epoch 1564 !\n",
      "\n",
      "Loss : 0.29320561495565234\n",
      "Starting epoch 1565 !\n",
      "\n",
      "Loss : 0.2974282719042836\n",
      "Starting epoch 1566 !\n",
      "\n",
      "Loss : 0.28500603428300547\n",
      "Starting epoch 1567 !\n",
      "\n",
      "Loss : 0.2921899759850534\n",
      "Starting epoch 1568 !\n",
      "\n",
      "Loss : 0.2615982551811909\n",
      "Starting epoch 1569 !\n",
      "\n",
      "Loss : 0.28426889771101427\n",
      "Starting epoch 1570 !\n",
      "\n",
      "Loss : 0.2914954272612017\n",
      "Starting epoch 1571 !\n",
      "\n",
      "Loss : 0.2770322617016682\n",
      "Starting epoch 1572 !\n",
      "\n",
      "Loss : 0.27811732340832146\n",
      "Starting epoch 1573 !\n",
      "\n",
      "Loss : 0.2764009177735468\n",
      "Starting epoch 1574 !\n",
      "\n",
      "Loss : 0.3003996759146249\n",
      "Starting epoch 1575 !\n",
      "\n",
      "Loss : 0.27891697942399657\n",
      "Starting epoch 1576 !\n",
      "\n",
      "Loss : 0.289037633281784\n",
      "Starting epoch 1577 !\n",
      "\n",
      "Loss : 0.28323907123840586\n",
      "Starting epoch 1578 !\n",
      "\n",
      "Loss : 0.2881594287345604\n",
      "Starting epoch 1579 !\n",
      "\n",
      "Loss : 0.30894939363205515\n",
      "Starting epoch 1580 !\n",
      "\n",
      "Loss : 0.30384701845191775\n",
      "Starting epoch 1581 !\n",
      "\n",
      "Loss : 0.2837550083086604\n",
      "Starting epoch 1582 !\n",
      "\n",
      "Loss : 0.2770872791202701\n",
      "Starting epoch 1583 !\n",
      "\n",
      "Loss : 0.27871825888144725\n",
      "Starting epoch 1584 !\n",
      "\n",
      "Loss : 0.2874287855462963\n",
      "Starting epoch 1585 !\n",
      "\n",
      "Loss : 0.2907911230917691\n",
      "Starting epoch 1586 !\n",
      "\n",
      "Loss : 0.27745090795009314\n",
      "Starting epoch 1587 !\n",
      "\n",
      "Loss : 0.27553464981670284\n",
      "Starting epoch 1588 !\n",
      "\n",
      "Loss : 0.28839792724267965\n",
      "Starting epoch 1589 !\n",
      "\n",
      "Loss : 0.2718207826014279\n",
      "Starting epoch 1590 !\n",
      "\n",
      "Loss : 0.27315486602637234\n",
      "Starting epoch 1591 !\n",
      "\n",
      "Loss : 0.27324410246647135\n",
      "Starting epoch 1592 !\n",
      "\n",
      "Loss : 0.29086517953142826\n",
      "Starting epoch 1593 !\n",
      "\n",
      "Loss : 0.31875878263290236\n",
      "Starting epoch 1594 !\n",
      "\n",
      "Loss : 0.2701049402204095\n",
      "Starting epoch 1595 !\n",
      "\n",
      "Loss : 0.27512441365187673\n",
      "Starting epoch 1596 !\n",
      "\n",
      "Loss : 0.2888273156317724\n",
      "Starting epoch 1597 !\n",
      "\n",
      "Loss : 0.27757190411188165\n",
      "Starting epoch 1598 !\n",
      "\n",
      "Loss : 0.28599685993121593\n",
      "Starting epoch 1599 !\n",
      "\n",
      "Loss : 0.29190357576827614\n",
      "Starting epoch 1600 !\n",
      "\n",
      "Loss : 0.272703846143622\n",
      "Starting epoch 1601 !\n",
      "\n",
      "Loss : 0.2880134178566284\n",
      "Starting epoch 1602 !\n",
      "\n",
      "Loss : 0.2649902316684626\n",
      "Starting epoch 1603 !\n",
      "\n",
      "Loss : 0.2826170924873579\n",
      "Starting epoch 1604 !\n",
      "\n",
      "Loss : 0.289318554914322\n",
      "Starting epoch 1605 !\n",
      "\n",
      "Loss : 0.28834488240330397\n",
      "Starting epoch 1606 !\n",
      "\n",
      "Loss : 0.29871372645404065\n",
      "Starting epoch 1607 !\n",
      "\n",
      "Loss : 0.2790526153177631\n",
      "Starting epoch 1608 !\n",
      "\n",
      "Loss : 0.27402822318531217\n",
      "Starting epoch 1609 !\n",
      "\n",
      "Loss : 0.28119781681773615\n",
      "Starting epoch 1610 !\n",
      "\n",
      "Loss : 0.2923563021380885\n",
      "Starting epoch 1611 !\n",
      "\n",
      "Loss : 0.26953993811189725\n",
      "Starting epoch 1612 !\n",
      "\n",
      "Loss : 0.282029484050209\n",
      "Starting epoch 1613 !\n",
      "\n",
      "Loss : 0.2820930436861758\n",
      "Starting epoch 1614 !\n",
      "\n",
      "Loss : 0.2816885790857328\n",
      "Starting epoch 1615 !\n",
      "\n",
      "Loss : 0.2799818086989072\n",
      "Starting epoch 1616 !\n",
      "\n",
      "Loss : 0.26615432558619245\n",
      "Starting epoch 1617 !\n",
      "\n",
      "Loss : 0.27904382761137014\n",
      "Starting epoch 1618 !\n",
      "\n",
      "Loss : 0.2821125540958375\n",
      "Starting epoch 1619 !\n",
      "\n",
      "Loss : 0.2990897890864586\n",
      "Starting epoch 1620 !\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.2647425607607073\n",
      "Starting epoch 1621 !\n",
      "\n",
      "Loss : 0.2749956376394447\n",
      "Starting epoch 1622 !\n",
      "\n",
      "Loss : 0.2771313609618719\n",
      "Starting epoch 1623 !\n",
      "\n",
      "Loss : 0.27909107460659377\n",
      "Starting epoch 1624 !\n",
      "\n",
      "Loss : 0.2873751575342652\n",
      "Starting epoch 1625 !\n",
      "\n",
      "Loss : 0.2824402002452993\n",
      "Starting epoch 1626 !\n",
      "\n",
      "Loss : 0.24921690322914902\n",
      "Starting epoch 1627 !\n",
      "\n",
      "Loss : 0.2870144164379762\n",
      "Starting epoch 1628 !\n",
      "\n",
      "Loss : 0.2868137491398117\n",
      "Starting epoch 1629 !\n",
      "\n",
      "Loss : 0.2758449509131665\n",
      "Starting epoch 1630 !\n",
      "\n",
      "Loss : 0.28647203621815664\n",
      "Starting epoch 1631 !\n",
      "\n",
      "Loss : 0.2590323603731029\n",
      "Starting epoch 1632 !\n",
      "\n",
      "Loss : 0.2638340712505944\n",
      "Starting epoch 1633 !\n",
      "\n",
      "Loss : 0.2624354557622047\n",
      "Starting epoch 1634 !\n",
      "\n",
      "Loss : 0.28767341096587734\n",
      "Starting epoch 1635 !\n",
      "\n",
      "Loss : 0.3002013628985606\n",
      "Starting epoch 1636 !\n",
      "\n",
      "Loss : 0.2785132013920213\n",
      "Starting epoch 1637 !\n",
      "\n",
      "Loss : 0.2813253433627336\n",
      "Starting epoch 1638 !\n",
      "\n",
      "Loss : 0.25142285772630957\n",
      "Starting epoch 1639 !\n",
      "\n",
      "Loss : 0.26641306336842424\n",
      "Starting epoch 1640 !\n",
      "\n",
      "Loss : 0.2782933045508099\n",
      "Starting epoch 1641 !\n",
      "\n",
      "Loss : 0.2733575132529752\n",
      "Starting epoch 1642 !\n",
      "\n",
      "Loss : 0.25167634697998464\n",
      "Starting epoch 1643 !\n",
      "\n",
      "Loss : 0.2775293303286137\n",
      "Starting epoch 1644 !\n",
      "\n",
      "Loss : 0.25837523700530024\n",
      "Starting epoch 1645 !\n",
      "\n",
      "Loss : 0.2837065534070641\n",
      "Starting epoch 1646 !\n",
      "\n",
      "Loss : 0.2692021942463051\n",
      "Starting epoch 1647 !\n",
      "\n",
      "Loss : 0.25973007308483936\n",
      "Starting epoch 1648 !\n",
      "\n",
      "Loss : 0.2731209183681984\n",
      "Starting epoch 1649 !\n",
      "\n",
      "Loss : 0.2620710804298216\n",
      "Starting epoch 1650 !\n",
      "\n",
      "Loss : 0.3035034295551631\n",
      "Starting epoch 1651 !\n",
      "\n",
      "Loss : 0.2728235190924333\n",
      "Starting epoch 1652 !\n",
      "\n",
      "Loss : 0.27322203148992696\n",
      "Starting epoch 1653 !\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-8c7266ca031f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-8c7266ca031f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net_q, net_k, train_dataloader, my_queue)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mp_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_k\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/inv/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/inv/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                    )\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/inv/lib/python3.7/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "N = batch_size\n",
    "C = 128\n",
    "def train(net_q, net_k, train_dataloader, my_queue):\n",
    "    # add args optimizer, epoch, temp=0.07\n",
    "    avg_loss = math.inf\n",
    "    m = 0.99\n",
    "    temp = 0.02\n",
    "    num_epochs = 2000\n",
    "    net_k = net_k.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net_q.parameters(), lr=3e-4)\n",
    "#     optimizer = torch.optim.SGD(net_q.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-6)\n",
    "    net_q.train()    \n",
    "    for epoch in range (720, num_epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        print(f\"Starting epoch {epoch} !\\n\")\n",
    "        for ((inputq, inputk), _) in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            x_q = net_q(inputq.to(device)).to(device)\n",
    "            x_q = nn.functional.normalize(x_q, dim=1)\n",
    "            x_k = None\n",
    "\n",
    "            with torch.no_grad():\n",
    "                x_k = net_k(inputk.to(device)).to(device)\n",
    "                x_k = nn.functional.normalize(x_k, dim=1)\n",
    "#                 x_k = x_k.detach()\n",
    "\n",
    "            l_pos = torch.bmm(x_q.view(N,1,C), x_k.view(N,C,1)).squeeze(-1)\n",
    "            l_neg = torch.mm(x_q.view(N,C), my_queue.data.clone().T.detach())\n",
    "\n",
    "\n",
    "            logits = torch.cat([l_pos, l_neg], dim=1)\n",
    "            logits /= temp\n",
    "\n",
    "            labels = torch.zeros([logits.shape[0]]).long().to(device)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                for p_q, p_k in zip(net_q.parameters(), net_k.parameters()):\n",
    "                    p_k.data.copy_(m*p_k.data + p_q.data*(1-m))\n",
    "\n",
    "            my_queue._dequeue_and_enqueue(x_k)\n",
    "#             my_queue.enqueue(x_k)\n",
    "#             my_queue.dequeue()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Loss : {total_loss / len(train_dataloader)}\")\n",
    "        writer.add_scalar('Moco loss',\n",
    "                            total_loss / len(train_dataloader),\n",
    "                            epoch)\n",
    "\n",
    "        if avg_loss > total_loss / (epoch + 1):\n",
    "            avg_loss = total_loss / (epoch + 1)\n",
    "            torch.save(net_q.state_dict(),\"./Untitled Folder/new_model_q_epoch_\"+str(epoch)+\".pt\")\n",
    "            torch.save(net_k.state_dict(),\"./Untitled Folder/new_model_k_epoch_\"+str(epoch)+\".pt\")\n",
    "\n",
    "\n",
    "\n",
    "image_queue = KeysQueue()\n",
    "for param in network_k.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "train(network_q, network_k, train_dataloader, image_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretext_network = Moco2(models.resnet50(num_classes=128))\n",
    "pretext_network.load_state_dict(torch.load(\"./Untitled Folder/new_model_q_epoch_1544.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "for param in pretext_network.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = 128\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "    ('fc1_a', nn.Linear(num_ftrs, 100)),\n",
    "    ('added_relu1_a', nn.ReLU(inplace=True)),\n",
    "    ('fc2_a', nn.Linear(100, 50)),\n",
    "    ('added_relu2_a', nn.ReLU(inplace=True)),\n",
    "    ('fc3_a', nn.Linear(50, 10))\n",
    "]))\n",
    "pretext_network.fc_lin = classifier\n",
    "\n",
    "\n",
    "\n",
    "# pretext_network.fc_gal = nn.Linear(num_ftrs, 10).to(device)\n",
    "pretext_network = pretext_network.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0 !\n",
      "\n",
      "acc: tensor(0.6118, device='cuda:0')\n",
      "loss: tensor(18.4260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 1 !\n",
      "\n",
      "acc: tensor(0.6841, device='cuda:0')\n",
      "loss: tensor(8.5645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 2 !\n",
      "\n",
      "acc: tensor(0.6744, device='cuda:0')\n",
      "loss: tensor(5.5370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 3 !\n",
      "\n",
      "acc: tensor(0.6350, device='cuda:0')\n",
      "loss: tensor(3.4422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 4 !\n",
      "\n",
      "acc: tensor(0.5574, device='cuda:0')\n",
      "loss: tensor(2.0352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 5 !\n",
      "\n",
      "acc: tensor(0.5787, device='cuda:0')\n",
      "loss: tensor(1.6543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 6 !\n",
      "\n",
      "acc: tensor(0.5864, device='cuda:0')\n",
      "loss: tensor(1.5037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 7 !\n",
      "\n",
      "acc: tensor(0.6261, device='cuda:0')\n",
      "loss: tensor(1.3682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 8 !\n",
      "\n",
      "acc: tensor(0.6483, device='cuda:0')\n",
      "loss: tensor(1.2858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 9 !\n",
      "\n",
      "acc: tensor(0.6650, device='cuda:0')\n",
      "loss: tensor(1.2443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 10 !\n",
      "\n",
      "acc: tensor(0.6931, device='cuda:0')\n",
      "loss: tensor(1.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 11 !\n",
      "\n",
      "acc: tensor(0.6948, device='cuda:0')\n",
      "loss: tensor(1.1421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 12 !\n",
      "\n",
      "acc: tensor(0.7026, device='cuda:0')\n",
      "loss: tensor(1.0913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 13 !\n",
      "\n",
      "acc: tensor(0.7034, device='cuda:0')\n",
      "loss: tensor(1.0889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 14 !\n",
      "\n",
      "acc: tensor(0.7176, device='cuda:0')\n",
      "loss: tensor(1.0474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 15 !\n",
      "\n",
      "acc: tensor(0.7238, device='cuda:0')\n",
      "loss: tensor(1.0368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 16 !\n",
      "\n",
      "acc: tensor(0.7244, device='cuda:0')\n",
      "loss: tensor(1.0116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 17 !\n",
      "\n",
      "acc: tensor(0.7201, device='cuda:0')\n",
      "loss: tensor(1.0236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 18 !\n",
      "\n",
      "acc: tensor(0.7280, device='cuda:0')\n",
      "loss: tensor(0.9975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 19 !\n",
      "\n",
      "acc: tensor(0.7276, device='cuda:0')\n",
      "loss: tensor(0.9955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 20 !\n",
      "\n",
      "acc: tensor(0.7422, device='cuda:0')\n",
      "loss: tensor(0.9346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 21 !\n",
      "\n",
      "acc: tensor(0.7415, device='cuda:0')\n",
      "loss: tensor(0.9325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 22 !\n",
      "\n",
      "acc: tensor(0.7421, device='cuda:0')\n",
      "loss: tensor(0.9169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 23 !\n",
      "\n",
      "acc: tensor(0.7518, device='cuda:0')\n",
      "loss: tensor(0.9085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 24 !\n",
      "\n",
      "acc: tensor(0.7622, device='cuda:0')\n",
      "loss: tensor(0.8842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 25 !\n",
      "\n",
      "acc: tensor(0.7604, device='cuda:0')\n",
      "loss: tensor(0.8917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 26 !\n",
      "\n",
      "acc: tensor(0.7583, device='cuda:0')\n",
      "loss: tensor(0.8429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 27 !\n",
      "\n",
      "acc: tensor(0.7677, device='cuda:0')\n",
      "loss: tensor(0.8365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 28 !\n",
      "\n",
      "acc: tensor(0.7665, device='cuda:0')\n",
      "loss: tensor(0.8286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 29 !\n",
      "\n",
      "acc: tensor(0.7773, device='cuda:0')\n",
      "loss: tensor(0.8192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 30 !\n",
      "\n",
      "acc: tensor(0.7810, device='cuda:0')\n",
      "loss: tensor(0.8054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 31 !\n",
      "\n",
      "acc: tensor(0.7802, device='cuda:0')\n",
      "loss: tensor(0.7744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 32 !\n",
      "\n",
      "acc: tensor(0.7776, device='cuda:0')\n",
      "loss: tensor(0.7745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 33 !\n",
      "\n",
      "acc: tensor(0.7917, device='cuda:0')\n",
      "loss: tensor(0.7633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 34 !\n",
      "\n",
      "acc: tensor(0.7861, device='cuda:0')\n",
      "loss: tensor(0.7295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 35 !\n",
      "\n",
      "acc: tensor(0.7845, device='cuda:0')\n",
      "loss: tensor(0.7342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 36 !\n",
      "\n",
      "acc: tensor(0.7939, device='cuda:0')\n",
      "loss: tensor(0.7227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 37 !\n",
      "\n",
      "acc: tensor(0.7939, device='cuda:0')\n",
      "loss: tensor(0.7205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 38 !\n",
      "\n",
      "acc: tensor(0.7912, device='cuda:0')\n",
      "loss: tensor(0.7075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 39 !\n",
      "\n",
      "acc: tensor(0.8012, device='cuda:0')\n",
      "loss: tensor(0.6896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 40 !\n",
      "\n",
      "acc: tensor(0.7940, device='cuda:0')\n",
      "loss: tensor(0.6923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 41 !\n",
      "\n",
      "acc: tensor(0.8013, device='cuda:0')\n",
      "loss: tensor(0.6677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 42 !\n",
      "\n",
      "acc: tensor(0.8012, device='cuda:0')\n",
      "loss: tensor(0.6803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 43 !\n",
      "\n",
      "acc: tensor(0.8016, device='cuda:0')\n",
      "loss: tensor(0.6681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 44 !\n",
      "\n",
      "acc: tensor(0.8039, device='cuda:0')\n",
      "loss: tensor(0.6531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 45 !\n",
      "\n",
      "acc: tensor(0.8069, device='cuda:0')\n",
      "loss: tensor(0.6635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 46 !\n",
      "\n",
      "acc: tensor(0.8074, device='cuda:0')\n",
      "loss: tensor(0.6392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 47 !\n",
      "\n",
      "acc: tensor(0.8173, device='cuda:0')\n",
      "loss: tensor(0.6212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 48 !\n",
      "\n",
      "acc: tensor(0.8073, device='cuda:0')\n",
      "loss: tensor(0.6406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 49 !\n",
      "\n",
      "acc: tensor(0.8132, device='cuda:0')\n",
      "loss: tensor(0.6196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 50 !\n",
      "\n",
      "acc: tensor(0.8118, device='cuda:0')\n",
      "loss: tensor(0.6222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 51 !\n",
      "\n",
      "acc: tensor(0.8217, device='cuda:0')\n",
      "loss: tensor(0.6053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 52 !\n",
      "\n",
      "acc: tensor(0.8193, device='cuda:0')\n",
      "loss: tensor(0.5972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 53 !\n",
      "\n",
      "acc: tensor(0.8160, device='cuda:0')\n",
      "loss: tensor(0.5982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 54 !\n",
      "\n",
      "acc: tensor(0.8162, device='cuda:0')\n",
      "loss: tensor(0.6160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 55 !\n",
      "\n",
      "acc: tensor(0.8119, device='cuda:0')\n",
      "loss: tensor(0.6119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 56 !\n",
      "\n",
      "acc: tensor(0.8167, device='cuda:0')\n",
      "loss: tensor(0.6173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 57 !\n",
      "\n",
      "acc: tensor(0.8248, device='cuda:0')\n",
      "loss: tensor(0.5770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 58 !\n",
      "\n",
      "acc: tensor(0.8175, device='cuda:0')\n",
      "loss: tensor(0.6032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 59 !\n",
      "\n",
      "acc: tensor(0.8262, device='cuda:0')\n",
      "loss: tensor(0.5797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 60 !\n",
      "\n",
      "acc: tensor(0.8244, device='cuda:0')\n",
      "loss: tensor(0.5661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 61 !\n",
      "\n",
      "acc: tensor(0.8294, device='cuda:0')\n",
      "loss: tensor(0.5804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 62 !\n",
      "\n",
      "acc: tensor(0.8313, device='cuda:0')\n",
      "loss: tensor(0.5603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 63 !\n",
      "\n",
      "acc: tensor(0.8292, device='cuda:0')\n",
      "loss: tensor(0.5726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 64 !\n",
      "\n",
      "acc: tensor(0.8275, device='cuda:0')\n",
      "loss: tensor(0.5609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 65 !\n",
      "\n",
      "acc: tensor(0.8306, device='cuda:0')\n",
      "loss: tensor(0.5566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 66 !\n",
      "\n",
      "acc: tensor(0.8301, device='cuda:0')\n",
      "loss: tensor(0.5498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 67 !\n",
      "\n",
      "acc: tensor(0.8240, device='cuda:0')\n",
      "loss: tensor(0.5686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 68 !\n",
      "\n",
      "acc: tensor(0.8329, device='cuda:0')\n",
      "loss: tensor(0.5453, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 69 !\n",
      "\n",
      "acc: tensor(0.8344, device='cuda:0')\n",
      "loss: tensor(0.5352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 70 !\n",
      "\n",
      "acc: tensor(0.8368, device='cuda:0')\n",
      "loss: tensor(0.5372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 71 !\n",
      "\n",
      "acc: tensor(0.8279, device='cuda:0')\n",
      "loss: tensor(0.5361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 72 !\n",
      "\n",
      "acc: tensor(0.8334, device='cuda:0')\n",
      "loss: tensor(0.5434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 73 !\n",
      "\n",
      "acc: tensor(0.8298, device='cuda:0')\n",
      "loss: tensor(0.5457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 74 !\n",
      "\n",
      "acc: tensor(0.8281, device='cuda:0')\n",
      "loss: tensor(0.5550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 75 !\n",
      "\n",
      "acc: tensor(0.8365, device='cuda:0')\n",
      "loss: tensor(0.5173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 76 !\n",
      "\n",
      "acc: tensor(0.8363, device='cuda:0')\n",
      "loss: tensor(0.5231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 77 !\n",
      "\n",
      "acc: tensor(0.8325, device='cuda:0')\n",
      "loss: tensor(0.5238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 78 !\n",
      "\n",
      "acc: tensor(0.8342, device='cuda:0')\n",
      "loss: tensor(0.5241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 79 !\n",
      "\n",
      "acc: tensor(0.8324, device='cuda:0')\n",
      "loss: tensor(0.5263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 80 !\n",
      "\n",
      "acc: tensor(0.8387, device='cuda:0')\n",
      "loss: tensor(0.5249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 81 !\n",
      "\n",
      "acc: tensor(0.8367, device='cuda:0')\n",
      "loss: tensor(0.5251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 82 !\n",
      "\n",
      "acc: tensor(0.8355, device='cuda:0')\n",
      "loss: tensor(0.5225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 83 !\n",
      "\n",
      "acc: tensor(0.8399, device='cuda:0')\n",
      "loss: tensor(0.5098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 84 !\n",
      "\n",
      "acc: tensor(0.8348, device='cuda:0')\n",
      "loss: tensor(0.5227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 85 !\n",
      "\n",
      "acc: tensor(0.8347, device='cuda:0')\n",
      "loss: tensor(0.5190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 86 !\n",
      "\n",
      "acc: tensor(0.8379, device='cuda:0')\n",
      "loss: tensor(0.5139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 87 !\n",
      "\n",
      "acc: tensor(0.8394, device='cuda:0')\n",
      "loss: tensor(0.5211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 88 !\n",
      "\n",
      "acc: tensor(0.8421, device='cuda:0')\n",
      "loss: tensor(0.5174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 89 !\n",
      "\n",
      "acc: tensor(0.8344, device='cuda:0')\n",
      "loss: tensor(0.5150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 90 !\n",
      "\n",
      "acc: tensor(0.8390, device='cuda:0')\n",
      "loss: tensor(0.5004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 91 !\n",
      "\n",
      "acc: tensor(0.8429, device='cuda:0')\n",
      "loss: tensor(0.5036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 92 !\n",
      "\n",
      "acc: tensor(0.8404, device='cuda:0')\n",
      "loss: tensor(0.5133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 93 !\n",
      "\n",
      "acc: tensor(0.8410, device='cuda:0')\n",
      "loss: tensor(0.4967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 94 !\n",
      "\n",
      "acc: tensor(0.8357, device='cuda:0')\n",
      "loss: tensor(0.5180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 95 !\n",
      "\n",
      "acc: tensor(0.8413, device='cuda:0')\n",
      "loss: tensor(0.5027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 96 !\n",
      "\n",
      "acc: tensor(0.8360, device='cuda:0')\n",
      "loss: tensor(0.5170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 97 !\n",
      "\n",
      "acc: tensor(0.8429, device='cuda:0')\n",
      "loss: tensor(0.5010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 98 !\n",
      "\n",
      "acc: tensor(0.8432, device='cuda:0')\n",
      "loss: tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 99 !\n",
      "\n",
      "acc: tensor(0.8386, device='cuda:0')\n",
      "loss: tensor(0.5088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 100 !\n",
      "\n",
      "acc: tensor(0.8424, device='cuda:0')\n",
      "loss: tensor(0.4978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 101 !\n",
      "\n",
      "acc: tensor(0.8406, device='cuda:0')\n",
      "loss: tensor(0.5007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 102 !\n",
      "\n",
      "acc: tensor(0.8404, device='cuda:0')\n",
      "loss: tensor(0.5018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 103 !\n",
      "\n",
      "acc: tensor(0.8386, device='cuda:0')\n",
      "loss: tensor(0.5111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 104 !\n",
      "\n",
      "acc: tensor(0.8367, device='cuda:0')\n",
      "loss: tensor(0.5078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 105 !\n",
      "\n",
      "acc: tensor(0.8485, device='cuda:0')\n",
      "loss: tensor(0.4880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 106 !\n",
      "\n",
      "acc: tensor(0.8487, device='cuda:0')\n",
      "loss: tensor(0.4838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 107 !\n",
      "\n",
      "acc: tensor(0.8466, device='cuda:0')\n",
      "loss: tensor(0.4924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 108 !\n",
      "\n",
      "acc: tensor(0.8425, device='cuda:0')\n",
      "loss: tensor(0.5006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 109 !\n",
      "\n",
      "acc: tensor(0.8460, device='cuda:0')\n",
      "loss: tensor(0.4873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 110 !\n",
      "\n",
      "acc: tensor(0.8440, device='cuda:0')\n",
      "loss: tensor(0.4913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 111 !\n",
      "\n",
      "acc: tensor(0.8387, device='cuda:0')\n",
      "loss: tensor(0.5010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 112 !\n",
      "\n",
      "acc: tensor(0.8442, device='cuda:0')\n",
      "loss: tensor(0.4879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 113 !\n",
      "\n",
      "acc: tensor(0.8445, device='cuda:0')\n",
      "loss: tensor(0.4891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 114 !\n",
      "\n",
      "acc: tensor(0.8394, device='cuda:0')\n",
      "loss: tensor(0.4986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 115 !\n",
      "\n",
      "acc: tensor(0.8470, device='cuda:0')\n",
      "loss: tensor(0.4916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 116 !\n",
      "\n",
      "acc: tensor(0.8470, device='cuda:0')\n",
      "loss: tensor(0.4827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 117 !\n",
      "\n",
      "acc: tensor(0.8465, device='cuda:0')\n",
      "loss: tensor(0.4825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 118 !\n",
      "\n",
      "acc: tensor(0.8462, device='cuda:0')\n",
      "loss: tensor(0.4820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 119 !\n",
      "\n",
      "acc: tensor(0.8462, device='cuda:0')\n",
      "loss: tensor(0.4828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 120 !\n",
      "\n",
      "acc: tensor(0.8451, device='cuda:0')\n",
      "loss: tensor(0.4867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 121 !\n",
      "\n",
      "acc: tensor(0.8488, device='cuda:0')\n",
      "loss: tensor(0.4830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 122 !\n",
      "\n",
      "acc: tensor(0.8488, device='cuda:0')\n",
      "loss: tensor(0.4747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 123 !\n",
      "\n",
      "acc: tensor(0.8481, device='cuda:0')\n",
      "loss: tensor(0.4750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 124 !\n",
      "\n",
      "acc: tensor(0.8469, device='cuda:0')\n",
      "loss: tensor(0.4885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 125 !\n",
      "\n",
      "acc: tensor(0.8440, device='cuda:0')\n",
      "loss: tensor(0.4889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 126 !\n",
      "\n",
      "acc: tensor(0.8490, device='cuda:0')\n",
      "loss: tensor(0.4867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 127 !\n",
      "\n",
      "acc: tensor(0.8430, device='cuda:0')\n",
      "loss: tensor(0.4913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 128 !\n",
      "\n",
      "acc: tensor(0.8481, device='cuda:0')\n",
      "loss: tensor(0.4835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 129 !\n",
      "\n",
      "acc: tensor(0.8486, device='cuda:0')\n",
      "loss: tensor(0.4635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 130 !\n",
      "\n",
      "acc: tensor(0.8488, device='cuda:0')\n",
      "loss: tensor(0.4747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 131 !\n",
      "\n",
      "acc: tensor(0.8457, device='cuda:0')\n",
      "loss: tensor(0.4820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 132 !\n",
      "\n",
      "acc: tensor(0.8495, device='cuda:0')\n",
      "loss: tensor(0.4740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 133 !\n",
      "\n",
      "acc: tensor(0.8467, device='cuda:0')\n",
      "loss: tensor(0.4782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 134 !\n",
      "\n",
      "acc: tensor(0.8490, device='cuda:0')\n",
      "loss: tensor(0.4638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 135 !\n",
      "\n",
      "acc: tensor(0.8517, device='cuda:0')\n",
      "loss: tensor(0.4716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 136 !\n",
      "\n",
      "acc: tensor(0.8501, device='cuda:0')\n",
      "loss: tensor(0.4785, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 137 !\n",
      "\n",
      "acc: tensor(0.8480, device='cuda:0')\n",
      "loss: tensor(0.4692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Starting epoch 138 !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "batch_size = 128\n",
    "train_dataloader_2 = torch.utils.data.DataLoader(\n",
    "        dataset_train,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=8,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    ")\n",
    "\n",
    "def train_after(net_q, train_dataloader):\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    parameters = list(filter(lambda p: p.requires_grad, net_q.parameters()))\n",
    "#     assert len(parameters) == 2  # fc.weight, fc.bias\n",
    "    optimizer = torch.optim.Adam(parameters, lr=3e-4)\n",
    "#     optimizer = torch.optim.SGD(parameters, lr=0.1, momentum=0.9, weight_decay=1e-6)\n",
    "    net_q.train()\n",
    "    \n",
    "    for epoch in range(1000):\n",
    "        acc = 0\n",
    "        total_loss = 0\n",
    "        print(f\"Starting epoch {epoch} !\\n\")\n",
    "        for ((inputq, _), labels) in train_dataloader:\n",
    "            \n",
    "            time0 = timeit.default_timer()\n",
    "            \n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            x_q = net_q(inputq.to(device)).to(device)\n",
    "            logits = net_q.fc_lin(x_q)\n",
    "            \n",
    "            time1 = timeit.default_timer()\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            pred = torch.argmax(logits,dim=-1)\n",
    "\n",
    "            acc += (labels == pred).sum() / (batch_size * len(train_dataloader))\n",
    "            total_loss+=loss\n",
    "            \n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "        total_loss = total_loss /  len(train_dataloader)\n",
    "        print(\"acc: \"+str(acc))\n",
    "        print(\"loss: \"+str(total_loss))\n",
    "        writer.add_scalar('Moco linear loss',\n",
    "                    total_loss / len(train_dataloader),\n",
    "                    epoch)\n",
    "\n",
    "        if 1:\n",
    "#             avg_loss = total_loss / (epoch + 1)\n",
    "            torch.save(net_q.state_dict(),\"./Untitled Folder/finished_model\"+str(epoch)+\".pt\")\n",
    "\n",
    "\n",
    "\n",
    "train_after(pretext_network, train_dataloader_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mguyshapira\u001b[0m (use `wandb login --relogin` to force relogin)\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
