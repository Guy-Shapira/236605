{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.utils import download_url\n",
    "import os\n",
    "import tarfile\n",
    "import hashlib\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import math\n",
    "\n",
    "\n",
    "# https://github.com/fastai/imagenette\n",
    "dataset_url = 'https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz'\n",
    "dataset_filename = dataset_url.split('/')[-1]\n",
    "dataset_foldername = dataset_filename.split('.')[0]\n",
    "data_path = './data'\n",
    "dataset_filepath = os.path.join(data_path,dataset_filename)\n",
    "dataset_folderpath = os.path.join(data_path,dataset_foldername)\n",
    "\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "download = False\n",
    "if not os.path.exists(dataset_filepath):\n",
    "    download = True\n",
    "else:\n",
    "    md5_hash = hashlib.md5()\n",
    "\n",
    "\n",
    "    file = open(dataset_filepath, \"rb\")\n",
    "\n",
    "    content = file.read()\n",
    "\n",
    "    md5_hash.update(content)\n",
    "\n",
    "\n",
    "    digest = md5_hash.hexdigest()\n",
    "    if digest != 'fe2fc210e6bb7c5664d602c3cd71e612':\n",
    "        download = True\n",
    "if download:\n",
    "    download_url(dataset_url, data_path)\n",
    "\n",
    "with tarfile.open(dataset_filepath, 'r:gz') as tar:\n",
    "    tar.extractall(path=data_path)\n",
    "    \n",
    "with open(\"tmp.txt\",'w') as tmp:\n",
    "    tmp.write(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuplicatedCompose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img1 = img.copy()\n",
    "        img2 = img.copy()\n",
    "        for t in self.transforms:\n",
    "            img1 = t(img1)\n",
    "            img2 = t(img2)\n",
    "        return img1, img2\n",
    "\n",
    "class TwoCropsTransform:\n",
    "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
    "\n",
    "    def __init__(self, base_transform):\n",
    "        self.base_transform = base_transform\n",
    "\n",
    "    def __call__(self, x):\n",
    "        q = self.base_transform(x)\n",
    "        k = self.base_transform(x)\n",
    "        return [q, k]\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + '(\\n\\t'\n",
    "        format_string += self.base_transform.__repr__().replace('\\n', '\\n\\t')\n",
    "        format_string += '\\n)'\n",
    "        return format_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/galsidi/miniconda3/envs/rambo6env/lib/python3.8/site-packages/torchvision/transforms/transforms.py:803: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "size  = 224\n",
    "ks = (int(0.1 * size) // 2) * 2 + 1 # should be odd\n",
    "__imagenet_stats = {'mean': [0.485, 0.456, 0.406],\n",
    "                    'std': [0.229, 0.224, 0.225]}\n",
    "\n",
    "train_transform = DuplicatedCompose([\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.1), ratio=(0.9, 1.1), interpolation=2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "\n",
    "# train_transform = TwoCropsTransform(transforms.Compose([transforms.RandomResizedCrop(scale=(0.2, 1), size=size),\n",
    "#                                       transforms.RandomHorizontalFlip(),\n",
    "#                                       transforms.RandomApply([transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)], p=0.8),\n",
    "#                                       transforms.RandomGrayscale(p=0.2),\n",
    "#                                       transforms.GaussianBlur(kernel_size=ks),\n",
    "#                                       transforms.ToTensor(),\n",
    "#                                       transforms.Normalize(**__imagenet_stats)]))\n",
    "\n",
    "dataset_train = torchvision.datasets.ImageFolder(os.path.join(dataset_folderpath,'train'), train_transform)\n",
    "dataset_test = torchvision.datasets.ImageFolder(os.path.join(dataset_folderpath,'val'), train_transform)\n",
    "#valid_ds = ImageFolder('./data/imagenette-160/val', valid_tfms)\n",
    "\n",
    "batch_size = 128\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset_train,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=8,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_numpy_samples(inputs):\n",
    "        mean = torch.as_tensor(__imagenet_stats['mean'], dtype=inputs.dtype, device=inputs.device)\n",
    "        std = torch.as_tensor(__imagenet_stats['std'], dtype=inputs.dtype, device=inputs.device)\n",
    "        inputs = inputs * std.view(1, -1, 1, 1) + mean.view(1, -1, 1, 1)\n",
    "        inputs = inputs.numpy()\n",
    "        inputs = np.transpose(inputs, (0,2,3,1))\n",
    "        return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "     \n",
    "# fig, axes = plt.subplots(nrows=batch_size, ncols=2, figsize=(10,100))\n",
    "# for (input1, input2), _ in train_dataloader:\n",
    "#     np_inputs1, np_inputs2 = get_numpy_samples(input1), get_numpy_samples(input2)\n",
    "#     for row in range(batch_size):\n",
    "#         axes[row, 0].axis(\"off\")\n",
    "#         axes[row, 0].imshow(np_inputs1[row])\n",
    "#         axes[row, 1].axis(\"off\")\n",
    "#         axes[row, 1].imshow(np_inputs2[row])\n",
    "#     break\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "def contrastive_loss(z1, z2, tau=0.2):\n",
    "    N = z1.shape[0]\n",
    "    logits = torch.mm(z1, z2.t())  # [N, N] pairs\n",
    "    labels = torch.arange(N).cuda()  # positives are in diagonal\n",
    "    loss = F.cross_entropy(logits / tau, labels)\n",
    "    return 2 * tau * loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "network_q = models.resnet50()\n",
    "network_k = models.resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 800\n",
    "dim = 1000\n",
    "\n",
    "class KeysQueue():\n",
    "    def __init__(self):\n",
    "        self.data = torch.randn(K, dim).cuda()\n",
    "    \n",
    "    def enqueue(self, k):\n",
    "        return torch.cat([self.data, k], dim=0)\n",
    "\n",
    "    def dequeue(self):\n",
    "        if len(self.data) > K:\n",
    "            return self.data[-K:]\n",
    "        else:\n",
    "            return self.data\n",
    "    def clone(self):\n",
    "        return self.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(40.3756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(40.4764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(36.9782, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(33.2539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(31.3089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(29.1649, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(27.1785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(25.2685, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(24.0952, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(22.8473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(21.8308, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(20.9320, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(20.1435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(19.4464, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(18.7094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(18.0100, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(17.3301, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(16.7165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(16.0634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(15.5596, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(14.9814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(14.3153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(13.6945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(13.2058, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(12.7726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(12.1876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(11.7206, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(11.3240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(10.8445, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(10.2674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(9.9413, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(9.5484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(9.1597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.7594, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.2882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.9938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.5642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.3128, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.8825, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-3ab2e4a40d49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mimage_queue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeysQueue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-3ab2e4a40d49>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net_q, net_k, train_dataloader, my_queue)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mx_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rambo6env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rambo6env/lib/python3.8/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rambo6env/lib/python3.8/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rambo6env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rambo6env/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rambo6env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rambo6env/lib/python3.8/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rambo6env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rambo6env/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rambo6env/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    393\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 395\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    396\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N = batch_size\n",
    "C = 1000\n",
    "\n",
    "def train(net_q, net_k, train_dataloader, my_queue):\n",
    "    # add args optimizer, epoch, temp=0.07\n",
    "    i = 0\n",
    "    total_loss = 0\n",
    "    avg_loss = math.inf\n",
    "    m = 0.999\n",
    "    temp = 0.07\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net_q.parameters(), lr=3e-4)\n",
    "    net_q.train()\n",
    "    net_k.eval() #updates using custom function by hand\n",
    "    for ((inputq, inputk), _) in train_dataloader:\n",
    "        i+=1\n",
    "#         inputq = inputq.cuda()\n",
    "#         inputk = inputk.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x_q = net_q(inputq).cuda()\n",
    "        x_q = nn.functional.normalize(x_q, dim=1)\n",
    "        x_k = net_k(inputk).cuda()\n",
    "        x_k = nn.functional.normalize(x_k, dim=1)\n",
    "        x_k = x_k.detach()\n",
    "        \n",
    "        l_pos = torch.einsum('nc,nc->n', [x_q, x_k]).unsqueeze(-1)\n",
    "        l_neg = torch.einsum('nc,ck->nk', [x_q, my_queue.clone().T.detach().cuda()])\n",
    "        \n",
    "        logits = torch.cat([l_pos, l_neg], dim=1)\n",
    "        logits /= temp\n",
    "        \n",
    "        labels = torch.zeros([logits.shape[0]]).long().cuda()\n",
    "#         print(labels.shape)\n",
    "#         print(logits.shape)\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        print(loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        for p_q, p_k in zip(net_q.parameters(), net_k.parameters()):\n",
    "            p_k.data.copy_(m*p_k.data + p_q.data*(1-m))\n",
    "        \n",
    "        my_queue.enqueue(x_k)\n",
    "        my_queue.dequeue()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        if avg_loss > total_loss / i:\n",
    "            avg_loss = total_loss / i\n",
    "            torch.save(net_q.state_dict(),\"./Untitled Folder/model_q_epoch_\"+str(i)+\".pt\")\n",
    "            torch.save(net_k.state_dict(),\"./Untitled Folder/model_k_epoch_\"+str(i)+\".pt\")\n",
    "\n",
    "\n",
    "\n",
    "image_queue = KeysQueue()\n",
    "train(network_q, network_k, train_dataloader, image_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretext_network = copy.deepcopy(network_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in pretext_network.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = 1000\n",
    "pretext_network.fc_gal = nn.Linear(num_ftrs, 10).cuda()\n",
    "pretext_network = pretext_network.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.0241, -0.0078, -0.0203,  ..., -0.0073,  0.0152,  0.0056],\n",
      "        [-0.0136, -0.0071, -0.0314,  ...,  0.0148,  0.0081, -0.0238],\n",
      "        [ 0.0262,  0.0196, -0.0162,  ...,  0.0108, -0.0262, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0385,  0.0258, -0.0101,  ..., -0.0251,  0.0211,  0.0172],\n",
      "        [ 0.0287, -0.0068, -0.0168,  ..., -0.0284,  0.0338, -0.0061],\n",
      "        [-0.0124, -0.0162, -0.0245,  ..., -0.0490,  0.0121, -0.0016]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0279,  0.0086,  0.0355, -0.0089,  0.0179, -0.0104,  0.0194,  0.0150,\n",
      "         0.0053, -0.0115], device='cuda:0', requires_grad=True)]\n",
      "acc: tensor(0.2102, device='cuda:0')\n",
      "loss: tensor(2.2088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "acc: tensor(0.2156, device='cuda:0')\n",
      "loss: tensor(2.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "acc: tensor(0.2148, device='cuda:0')\n",
      "loss: tensor(2.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "acc: tensor(0.2176, device='cuda:0')\n",
      "loss: tensor(2.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "acc: tensor(0.2240, device='cuda:0')\n",
      "loss: tensor(2.1704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "acc: tensor(0.2251, device='cuda:0')\n",
      "loss: tensor(2.1634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "acc: tensor(0.2181, device='cuda:0')\n",
      "loss: tensor(2.1711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "acc: tensor(0.2130, device='cuda:0')\n",
      "loss: tensor(2.1687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "acc: tensor(0.2204, device='cuda:0')\n",
      "loss: tensor(2.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "acc: tensor(0.2178, device='cuda:0')\n",
      "loss: tensor(2.1780, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def train_after(net_q, train_dataloader):\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    parameters = list(filter(lambda p: p.requires_grad, net_q.parameters()))\n",
    "    assert len(parameters) == 2  # fc.weight, fc.bias\n",
    "    print(parameters)\n",
    "    optimizer = torch.optim.Adam(parameters, lr=0.0003)\n",
    "    #optimizer = torch.optim.SGD(net_q.parameters(), lr=1e-6)\n",
    "    net_q.train()\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        acc = 0\n",
    "        total_loss = 0\n",
    "        for ((inputq, _), labels) in train_dataloader:\n",
    "            labels = labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            x_q = net_q(inputq.cuda())\n",
    "            logits = net_q.fc_gal(x_q)\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            pred = torch.argmax(logits,dim=-1)\n",
    "\n",
    "            acc += (labels == pred).sum() / (batch_size * len(train_dataloader))\n",
    "            total_loss+=loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "#         acc = acc / len(train_dataloader)\n",
    "        total_loss = total_loss /  len(train_dataloader)\n",
    "        print(\"acc: \"+str(acc))\n",
    "        print(\"loss: \"+str(total_loss))\n",
    "\n",
    "\n",
    "\n",
    "train_after(pretext_network, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
